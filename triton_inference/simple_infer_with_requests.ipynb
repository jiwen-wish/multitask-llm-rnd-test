{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'densenet_onnx',\n",
       " 'platform': 'onnxruntime_onnx',\n",
       " 'backend': 'onnxruntime',\n",
       " 'version_policy': {'latest': {'num_versions': 1}},\n",
       " 'max_batch_size': 0,\n",
       " 'input': [{'name': 'data_0',\n",
       "   'data_type': 'TYPE_FP32',\n",
       "   'format': 'FORMAT_NONE',\n",
       "   'dims': [1, 3, 224, 224],\n",
       "   'is_shape_tensor': False,\n",
       "   'allow_ragged_batch': False,\n",
       "   'optional': False}],\n",
       " 'output': [{'name': 'fc6_1',\n",
       "   'data_type': 'TYPE_FP32',\n",
       "   'dims': [1, 1000, 1, 1],\n",
       "   'label_filename': '',\n",
       "   'is_shape_tensor': False}],\n",
       " 'batch_input': [],\n",
       " 'batch_output': [],\n",
       " 'optimization': {'priority': 'PRIORITY_DEFAULT',\n",
       "  'input_pinned_memory': {'enable': True},\n",
       "  'output_pinned_memory': {'enable': True},\n",
       "  'gather_kernel_buffer_threshold': 0,\n",
       "  'eager_batching': False},\n",
       " 'instance_group': [{'name': 'densenet_onnx',\n",
       "   'kind': 'KIND_GPU',\n",
       "   'count': 1,\n",
       "   'gpus': [0],\n",
       "   'secondary_devices': [],\n",
       "   'profile': [],\n",
       "   'passive': False,\n",
       "   'host_policy': ''}],\n",
       " 'default_model_filename': 'model.onnx',\n",
       " 'cc_model_filenames': {},\n",
       " 'metric_tags': {},\n",
       " 'parameters': {},\n",
       " 'model_warmup': []}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get('http://localhost:8000/v2/models/densenet_onnx/config').json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_json = {\n",
    "   \"inputs\":[\n",
    "      {\t\n",
    "      \"name\": \"data_0\",\n",
    "      \"shape\": [1, 3, 224, 224],\n",
    "      \"datatype\": \"FP32\",\n",
    "      \"data\": np.random.random((1, 3, 224, 224)).tolist()\n",
    "      }\n",
    "   ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.post('http://localhost:8000/v2/models/densenet_onnx/versions/1/infer', json=input_json).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name', 'model_version', 'outputs'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145 ms ± 1.76 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "res = requests.post('http://localhost:8000/v2/models/densenet_onnx/versions/1/infer', json=input_json).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3.8 -m transformers.onnx --model=distilbert-base-uncased onnx/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'distilbert_onnx',\n",
       " 'platform': 'onnxruntime_onnx',\n",
       " 'backend': 'onnxruntime',\n",
       " 'version_policy': {'latest': {'num_versions': 1}},\n",
       " 'max_batch_size': 4,\n",
       " 'input': [{'name': 'attention_mask',\n",
       "   'data_type': 'TYPE_INT64',\n",
       "   'format': 'FORMAT_NONE',\n",
       "   'dims': [-1],\n",
       "   'is_shape_tensor': False,\n",
       "   'allow_ragged_batch': False,\n",
       "   'optional': False},\n",
       "  {'name': 'input_ids',\n",
       "   'data_type': 'TYPE_INT64',\n",
       "   'format': 'FORMAT_NONE',\n",
       "   'dims': [-1],\n",
       "   'is_shape_tensor': False,\n",
       "   'allow_ragged_batch': False,\n",
       "   'optional': False}],\n",
       " 'output': [{'name': 'last_hidden_state',\n",
       "   'data_type': 'TYPE_FP32',\n",
       "   'dims': [-1, 768],\n",
       "   'label_filename': '',\n",
       "   'is_shape_tensor': False}],\n",
       " 'batch_input': [],\n",
       " 'batch_output': [],\n",
       " 'optimization': {'priority': 'PRIORITY_DEFAULT',\n",
       "  'input_pinned_memory': {'enable': True},\n",
       "  'output_pinned_memory': {'enable': True},\n",
       "  'gather_kernel_buffer_threshold': 0,\n",
       "  'eager_batching': False},\n",
       " 'dynamic_batching': {'preferred_batch_size': [4],\n",
       "  'max_queue_delay_microseconds': 0,\n",
       "  'preserve_ordering': False,\n",
       "  'priority_levels': 0,\n",
       "  'default_priority_level': 0,\n",
       "  'priority_queue_policy': {}},\n",
       " 'instance_group': [{'name': 'distilbert_onnx',\n",
       "   'kind': 'KIND_GPU',\n",
       "   'count': 1,\n",
       "   'gpus': [0],\n",
       "   'secondary_devices': [],\n",
       "   'profile': [],\n",
       "   'passive': False,\n",
       "   'host_policy': ''}],\n",
       " 'default_model_filename': 'model.onnx',\n",
       " 'cc_model_filenames': {},\n",
       " 'metric_tags': {},\n",
       " 'parameters': {},\n",
       " 'model_warmup': []}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get('http://localhost:8000/v2/models/distilbert_onnx/config').json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_json = {\n",
    "   \"inputs\":[\n",
    "      {\t\n",
    "         \"name\": \"attention_mask\",\n",
    "         \"shape\": [1, 4],\n",
    "         \"datatype\": \"INT64\",\n",
    "         \"data\": [[1, 1, 1, 1]]\n",
    "      },\n",
    "      {\t\n",
    "         \"name\": \"input_ids\",\n",
    "         \"shape\": [1, 4],\n",
    "         \"datatype\": \"INT64\",\n",
    "         \"data\": [[1, 1, 1, 1]]\n",
    "      }\n",
    "   ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.2 ms ± 163 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "res = requests.post('http://localhost:8000/v2/models/distilbert_onnx/versions/1/infer', json=input_json).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.post('http://localhost:8000/v2/models/distilbert_onnx/versions/1/infer', json=input_json).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name', 'model_version', 'outputs'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import s3fs\n",
    "fs = s3fs.S3FileSystem()\n",
    "fs.get('structured-data-dev/coeus-gpu-multitask-ml/query-classify/v3/', 'query_classify', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.13.1-cp38-cp38-manylinux1_x86_64.whl (887.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 887.4 MB 1.1 kB/s  eta 0:00:011     |███▋                            | 100.5 MB 83.2 MB/s eta 0:00:10        | 148.9 MB 83.2 MB/s eta 0:00:09     |██████▌                         | 181.6 MB 83.2 MB/s eta 0:00:09     |██████████████████████████████▍ | 841.3 MB 83.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.5.0)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\"\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[K     |████████████████████████████████| 849 kB 93.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\"\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 557.1 MB 6.4 kB/s s eta 0:00:01     |█████████████████████████████▊  | 518.2 MB 104.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\"\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 317.1 MB 18 kB/s s eta 0:00:01    |█▉                              | 18.1 MB 81.0 MB/s eta 0:00:04     |█████████████████████████████   | 286.4 MB 83.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\"\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 21.0 MB 61.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\"->torch) (63.2.0)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\"->torch) (0.37.1)\n",
      "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, nvidia-cuda-nvrtc-cu11, torch\n",
      "Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local PyTorch model found.\n",
      "Framework not requested. Using torch to export to ONNX.\n",
      "Using framework PyTorch: 1.13.1+cu117\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> False\n",
      "Validating ONNX model...\n",
      "\t-[✓] ONNX model output names match reference model ({'logits'})\n",
      "\t- Validating ONNX Model output \"logits\":\n",
      "\t\t-[✓] (3, 6037) matches (3, 6037)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "All good, model saved at: query_classify_onnx/model.onnx\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/onnx/__main__.py:178: FutureWarning: The export was done by transformers.onnx which is deprecated and will be removed in v5. We recommend using optimum.exporters.onnx in future. You can find more information here: https://huggingface.co/docs/optimum/exporters/onnx/usage_guides/export_a_model.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "!python3.8 -m transformers.onnx --model=query_classify --feature=sequence-classification query_classify_onnx/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (2.22.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'query_classify_onnx',\n",
       " 'platform': 'onnxruntime_onnx',\n",
       " 'backend': 'onnxruntime',\n",
       " 'version_policy': {'latest': {'num_versions': 1}},\n",
       " 'max_batch_size': 4,\n",
       " 'input': [{'name': 'attention_mask',\n",
       "   'data_type': 'TYPE_INT64',\n",
       "   'format': 'FORMAT_NONE',\n",
       "   'dims': [-1],\n",
       "   'is_shape_tensor': False,\n",
       "   'allow_ragged_batch': False,\n",
       "   'optional': False},\n",
       "  {'name': 'input_ids',\n",
       "   'data_type': 'TYPE_INT64',\n",
       "   'format': 'FORMAT_NONE',\n",
       "   'dims': [-1],\n",
       "   'is_shape_tensor': False,\n",
       "   'allow_ragged_batch': False,\n",
       "   'optional': False}],\n",
       " 'output': [{'name': 'logits',\n",
       "   'data_type': 'TYPE_FP32',\n",
       "   'dims': [6037],\n",
       "   'label_filename': '',\n",
       "   'is_shape_tensor': False}],\n",
       " 'batch_input': [],\n",
       " 'batch_output': [],\n",
       " 'optimization': {'priority': 'PRIORITY_DEFAULT',\n",
       "  'input_pinned_memory': {'enable': True},\n",
       "  'output_pinned_memory': {'enable': True},\n",
       "  'gather_kernel_buffer_threshold': 0,\n",
       "  'eager_batching': False},\n",
       " 'dynamic_batching': {'preferred_batch_size': [4],\n",
       "  'max_queue_delay_microseconds': 0,\n",
       "  'preserve_ordering': False,\n",
       "  'priority_levels': 0,\n",
       "  'default_priority_level': 0,\n",
       "  'priority_queue_policy': {}},\n",
       " 'instance_group': [{'name': 'query_classify_onnx',\n",
       "   'kind': 'KIND_GPU',\n",
       "   'count': 1,\n",
       "   'gpus': [0],\n",
       "   'secondary_devices': [],\n",
       "   'profile': [],\n",
       "   'passive': False,\n",
       "   'host_policy': ''}],\n",
       " 'default_model_filename': 'model.onnx',\n",
       " 'cc_model_filenames': {},\n",
       " 'metric_tags': {},\n",
       " 'parameters': {},\n",
       " 'model_warmup': []}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get('http://localhost:8000/v2/models/query_classify_onnx/config').json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_json = {\n",
    "   \"inputs\":[\n",
    "      {\t\n",
    "         \"name\": \"attention_mask\",\n",
    "         \"shape\": [1, 60],\n",
    "         \"datatype\": \"INT64\",\n",
    "         \"data\": [[1, 1, 1, 1] * 15]\n",
    "      },\n",
    "      {\t\n",
    "         \"name\": \"input_ids\",\n",
    "         \"shape\": [1, 60],\n",
    "         \"datatype\": \"INT64\",\n",
    "         \"data\": [[1, 1, 1, 1] * 15]\n",
    "      }\n",
    "   ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.post('http://localhost:8000/v2/models/query_classify_onnx/versions/1/infer', json=input_json).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name', 'model_version', 'outputs'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.5 ms ± 140 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "res = requests.post('http://localhost:8000/v2/models/query_classify_onnx/versions/1/infer', json=input_json).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
