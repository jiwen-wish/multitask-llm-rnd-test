{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coeus_model_registry_client import ModelRegistryClient, SupportedLibraries\n",
    "from onnxconverter_common import data_types as onnx_data_types\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../modelling/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_multitask_multimodal import LLM_MultitaskMultimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint  latest  pytorch_model.bin  zero_to_fp32.py\n"
     ]
    }
   ],
   "source": [
    "!ls ../modelling/models/multitask_multimodal_multilingual/version_9/epoch=1-step=2600.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = os.path.abspath('../modelling/models/multitask_multimodal_multilingual/version_9/epoch=1-step=2600.ckpt/pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd299bcc4294c6e95f06fb9d37dd9f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/702 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Unused kwargs when getting google/mt5-base: {'distance_func': 'cosine', 'loss_type': 'cross-entropy', 'margin': None, 'hidden_states_type': 'encoder-last', 'add_simcse': False, 'manual_loss_type': 'manual_mse', 'auto_task_weight': False, 'multitask_specs_dict': {'clm_singlemodal_wishquery2tax': None}, 'head_dict': {}}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "795d46b6a1c6478aaf7b99194b46f7f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/376 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb5ef40e7bc48dbaf0583d8b1fe97bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5735fb1cff4df18586ba654cd730f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py38/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = LLM_MultitaskMultimodal.load_from_checkpoint(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "namespace = 'default-gpu'\n",
    "model_name = 'multitask-nlp-queryclassify-v2-test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating client with cert\n"
     ]
    },
    {
     "ename": "ServerError",
     "evalue": "UNAVAILABLE - DNS resolution failed for coeus-model-registry.s.legacy.wish.site:8081: C-ares status is not ARES_SUCCESS qtype=A name=coeus-model-registry.s.legacy.wish.site is_balancer=0: Domain name not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServerError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m ModelRegistryClient() \u001b[39mas\u001b[39;00m coeus:\n\u001b[0;32m----> 2\u001b[0m     coeus\u001b[39m.\u001b[39;49mget_models(namespace)\n",
      "File \u001b[0;32m/opt/conda/envs/py38/lib/python3.8/site-packages/coeus_model_registry_client/exceptions.py:44\u001b[0m, in \u001b[0;36mhandle_grpc_errors.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# call decorated function and return result\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39m_channel\u001b[39m.\u001b[39m_InactiveRpcError \u001b[39mas\u001b[39;00m rpc_error:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[39m# catch grpc._channel._InactiveRpcError and wrap it as a ServerException\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     \u001b[39mraise\u001b[39;00m ServerError(rpc_error\u001b[39m.\u001b[39mcode(), rpc_error\u001b[39m.\u001b[39mdetails()) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mServerError\u001b[0m: UNAVAILABLE - DNS resolution failed for coeus-model-registry.s.legacy.wish.site:8081: C-ares status is not ARES_SUCCESS qtype=A name=coeus-model-registry.s.legacy.wish.site is_balancer=0: Domain name not found"
     ]
    }
   ],
   "source": [
    "with ModelRegistryClient() as coeus:\n",
    "    coeus.get_models(namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default ModelRegistryClient() returns a client with prod env and default namespace\n",
    "model_registry_client = ModelRegistryClient()\n",
    " \n",
    "# train or load your own tf model here\n",
    "\n",
    "inputs = {input_tensor.name: input_tensor}\n",
    "outputs = {output_tensor.name: output_tensor}\n",
    "doc_string = 'multitask-nlp-queryclassify-v2-test'  # doc string is optional\n",
    " \n",
    "# save model to registry\n",
    "model_registry_client.save_model(namespace, model_name, '0.0.1', SupportedLibraries.TENSORFLOW_1,\n",
    "                 session, inputs, outputs, doc_string)\n",
    "# deploy model for inference\n",
    "model_registry_client.deploy_model(namespace, model_name, '0.0.1')\n",
    " \n",
    "# check the latest model version\n",
    "desired_model_version_tf = model_registry_client.get_model_desired_version(namespace, model_name) # will be 0.0.1\n",
    " \n",
    "# get a list of all the models in a namespace\n",
    "models = model_registry_client.get_models(namespace)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ea19d11efa7602c1f12500925a974ed4f31fcf847bd6f694bd5180da2602ded"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
