{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "version2inferfile_tax = {\n",
    "    'emb_v0.0': \"../../models/product_title_embedding/version_0/epoch=4-step=370604--wish-newtax-v1.2.1.json\", \n",
    "    'emb_v0.4': \"../../models/product_title_embedding/version_4/epoch=4-step=398293--wish-newtax-v1.2.1.json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "version2inferfile = {\n",
    "    'clm_v0.4_aliprompt': \"../../models/product_title_taxonomy_classification/version_4/epoch=0-step=996156--wish-offshore-validated-test-aliprompt.json\",\n",
    "    'clm_v0.4_wishprompt': \"../../models/product_title_taxonomy_classification/version_4/epoch=0-step=996156--wish-offshore-validated-test-wishprompt.json\",\n",
    "    'clm_v0.5_aliprompt': \"../../models/product_title_taxonomy_classification/version_5/epoch=1-step=1006577--wish-offshore-validated-test-aliprompt.json\",\n",
    "    'clm_v0.5_wishprompt': \"../../models/product_title_taxonomy_classification/version_5/epoch=1-step=1006577--wish-offshore-validated-test-wishprompt.json\",\n",
    "    'emb_v0.0': \"../../models/product_title_embedding/version_0/epoch=4-step=370604--wish-offshore-validated-test.json\",\n",
    "    'emb_v0.4': \"../../models/product_title_embedding/version_4/epoch=4-step=398293--wish-offshore-validated-test.json\",\n",
    "    'seqclf_v0.0': \"../../models/product_title_taxonomy_sequence_classification/version_0/seqclf-epoch=4-step=59300--wish-offshore-validated-test.json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "version2distance_func = {\n",
    "    'emb_v0.0': 'cosine',\n",
    "    'emb_v0.4': 'order'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "version2decode_method = {\n",
    "    'seqclf_v0.0': 'leaf'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_from_file import perf_eval_util, get_df_outfile, read_json_helper\n",
    "from eval_from_file_emb import perf_eval_util_emb\n",
    "from eval_from_file_seqclf import perf_eval_utils_seqclf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"offshore-validated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map_file = \"../../datasets/taxonomy/wish_v1.2.1_newtax_allpaths.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_data_func = lambda df_data: df_data[df_data.category.apply(lambda x: x[0] not in ['apparel accessories', 'automobiles & motorcycles'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 4/7 [00:14<00:09,  3.24s/it]/workspaces/multitask-llm-rnd/modelling/notebooks/eval/eval_from_file.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tmp_model'] = df[model].apply(lambda x: x[:level] if len(x[:level]) > 0 else x[:1])\n",
      "/workspaces/multitask-llm-rnd/modelling/notebooks/eval/eval_from_file.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tmp_label'] = df[labeler].apply(lambda x: x[:level] if len(x[:level]) > 0 else x[:1])\n",
      "/workspaces/multitask-llm-rnd/modelling/notebooks/eval/eval_from_file.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tmp_model'] = df[model].apply(lambda x: x[:level] if len(x[:level]) > 0 else x[:1])\n",
      "/workspaces/multitask-llm-rnd/modelling/notebooks/eval/eval_from_file.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tmp_label'] = df[labeler].apply(lambda x: x[:level] if len(x[:level]) > 0 else x[:1])\n",
      " 71%|███████▏  | 5/7 [00:28<00:14,  7.14s/it]WARNING:root:cuda eval failed with CUDA out of memory. Tried to allocate 47.16 GiB (GPU 0; 15.77 GiB total capacity; 56.00 MiB already allocated; 14.55 GiB free; 68.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, try with cpu\n",
      "INFO:asyncssh:Opening SSH connection to github.com, port 22\n",
      "INFO:asyncssh:[conn=21] Connected to SSH server at github.com, port 22\n",
      "INFO:asyncssh:[conn=21]   Local address: 192.168.0.2, port 57850\n",
      "INFO:asyncssh:[conn=21]   Peer address: 140.82.114.4, port 22\n",
      "INFO:asyncssh:[conn=21] Beginning auth for user git\n",
      "INFO:asyncssh:[conn=21] Auth for user git succeeded\n",
      "INFO:asyncssh:[conn=21, chan=0] Requesting new SSH session\n",
      "INFO:asyncssh:[conn=21, chan=0]   Command: git-upload-pack '/junwang-wish/query_understanding_data.git'\n",
      "INFO:asyncssh:[conn=21] Closing connection\n",
      "INFO:asyncssh:[conn=21, chan=0] Closing channel\n",
      "INFO:asyncssh:[conn=21] Sending disconnect: Disconnected by application (11)\n",
      "INFO:asyncssh:[conn=21] Connection closed\n",
      "INFO:asyncssh:[conn=21, chan=0] Closing channel due to connection close\n",
      "INFO:asyncssh:[conn=21, chan=0] Channel closed\n",
      "INFO:asyncssh:Opening SSH connection to github.com, port 22\n",
      "INFO:asyncssh:[conn=22] Connected to SSH server at github.com, port 22\n",
      "INFO:asyncssh:[conn=22]   Local address: 192.168.0.2, port 33242\n",
      "INFO:asyncssh:[conn=22]   Peer address: 140.82.113.3, port 22\n",
      "INFO:asyncssh:[conn=22] Beginning auth for user git\n",
      "INFO:asyncssh:[conn=22] Auth for user git succeeded\n",
      "INFO:asyncssh:[conn=22, chan=0] Requesting new SSH session\n",
      "INFO:asyncssh:[conn=22, chan=0]   Command: git-upload-pack '/junwang-wish/query_understanding_data.git'\n",
      "INFO:asyncssh:[conn=22] Closing connection\n",
      "INFO:asyncssh:[conn=22, chan=0] Closing channel\n",
      "INFO:asyncssh:[conn=22] Sending disconnect: Disconnected by application (11)\n",
      "INFO:asyncssh:[conn=22] Connection closed\n",
      "INFO:asyncssh:[conn=22, chan=0] Closing channel due to connection close\n",
      "INFO:asyncssh:[conn=22, chan=0] Channel closed\n",
      "INFO:asyncssh:Opening SSH connection to github.com, port 22\n",
      "INFO:asyncssh:[conn=23] Connected to SSH server at github.com, port 22\n",
      "INFO:asyncssh:[conn=23]   Local address: 192.168.0.2, port 40608\n",
      "INFO:asyncssh:[conn=23]   Peer address: 140.82.114.3, port 22\n",
      "INFO:asyncssh:[conn=23] Beginning auth for user git\n",
      "INFO:asyncssh:[conn=23] Auth for user git succeeded\n",
      "INFO:asyncssh:[conn=23, chan=0] Requesting new SSH session\n",
      "INFO:asyncssh:[conn=23, chan=0]   Command: git-upload-pack '/junwang-wish/query_understanding_data.git'\n",
      "INFO:asyncssh:[conn=23] Closing connection\n",
      "INFO:asyncssh:[conn=23, chan=0] Closing channel\n",
      "INFO:asyncssh:[conn=23] Sending disconnect: Disconnected by application (11)\n",
      "INFO:asyncssh:[conn=23] Connection closed\n",
      "INFO:asyncssh:[conn=23, chan=0] Closing channel due to connection close\n",
      "INFO:asyncssh:[conn=23, chan=0] Channel closed\n",
      " 86%|████████▌ | 6/7 [01:08<00:18, 18.57s/it]INFO:asyncssh:Opening SSH connection to github.com, port 22\n",
      "INFO:asyncssh:[conn=24] Connected to SSH server at github.com, port 22\n",
      "INFO:asyncssh:[conn=24]   Local address: 192.168.0.2, port 40612\n",
      "INFO:asyncssh:[conn=24]   Peer address: 140.82.114.3, port 22\n",
      "INFO:asyncssh:[conn=24] Beginning auth for user git\n",
      "INFO:asyncssh:[conn=24] Auth for user git succeeded\n",
      "INFO:asyncssh:[conn=24, chan=0] Requesting new SSH session\n",
      "INFO:asyncssh:[conn=24, chan=0]   Command: git-upload-pack '/junwang-wish/query_understanding_data.git'\n",
      "INFO:asyncssh:[conn=24] Closing connection\n",
      "INFO:asyncssh:[conn=24, chan=0] Closing channel\n",
      "INFO:asyncssh:[conn=24] Sending disconnect: Disconnected by application (11)\n",
      "INFO:asyncssh:[conn=24] Connection closed\n",
      "INFO:asyncssh:[conn=24, chan=0] Closing channel due to connection close\n",
      "INFO:asyncssh:[conn=24, chan=0] Channel closed\n",
      "INFO:asyncssh:Opening SSH connection to github.com, port 22\n",
      "INFO:asyncssh:[conn=25] Connected to SSH server at github.com, port 22\n",
      "INFO:asyncssh:[conn=25]   Local address: 192.168.0.2, port 59094\n",
      "INFO:asyncssh:[conn=25]   Peer address: 140.82.113.4, port 22\n",
      "INFO:asyncssh:[conn=25] Beginning auth for user git\n",
      "INFO:asyncssh:[conn=25] Auth for user git succeeded\n",
      "INFO:asyncssh:[conn=25, chan=0] Requesting new SSH session\n",
      "INFO:asyncssh:[conn=25, chan=0]   Command: git-upload-pack '/junwang-wish/query_understanding_data.git'\n",
      "INFO:asyncssh:[conn=25] Closing connection\n",
      "INFO:asyncssh:[conn=25, chan=0] Closing channel\n",
      "INFO:asyncssh:[conn=25] Sending disconnect: Disconnected by application (11)\n",
      "INFO:asyncssh:[conn=25] Connection closed\n",
      "INFO:asyncssh:[conn=25, chan=0] Closing channel due to connection close\n",
      "INFO:asyncssh:[conn=25, chan=0] Channel closed\n",
      "INFO:asyncssh:Opening SSH connection to github.com, port 22\n",
      "INFO:asyncssh:[conn=26] Connected to SSH server at github.com, port 22\n",
      "INFO:asyncssh:[conn=26]   Local address: 192.168.0.2, port 59096\n",
      "INFO:asyncssh:[conn=26]   Peer address: 140.82.113.4, port 22\n",
      "INFO:asyncssh:[conn=26] Beginning auth for user git\n",
      "INFO:asyncssh:[conn=26] Auth for user git succeeded\n",
      "INFO:asyncssh:[conn=26, chan=0] Requesting new SSH session\n",
      "INFO:asyncssh:[conn=26, chan=0]   Command: git-upload-pack '/junwang-wish/query_understanding_data.git'\n",
      "INFO:asyncssh:[conn=26] Closing connection\n",
      "INFO:asyncssh:[conn=26, chan=0] Closing channel\n",
      "INFO:asyncssh:[conn=26] Sending disconnect: Disconnected by application (11)\n",
      "INFO:asyncssh:[conn=26] Connection closed\n",
      "INFO:asyncssh:[conn=26, chan=0] Closing channel due to connection close\n",
      "INFO:asyncssh:[conn=26, chan=0] Channel closed\n",
      "INFO:asyncssh:Opening SSH connection to github.com, port 22\n",
      "INFO:asyncssh:[conn=27] Connected to SSH server at github.com, port 22\n",
      "INFO:asyncssh:[conn=27]   Local address: 192.168.0.2, port 40618\n",
      "INFO:asyncssh:[conn=27]   Peer address: 140.82.114.3, port 22\n",
      "INFO:asyncssh:[conn=27] Beginning auth for user git\n",
      "INFO:asyncssh:[conn=27] Auth for user git succeeded\n",
      "INFO:asyncssh:[conn=27, chan=0] Requesting new SSH session\n",
      "INFO:asyncssh:[conn=27, chan=0]   Command: git-upload-pack '/junwang-wish/query_understanding_data.git'\n",
      "INFO:asyncssh:[conn=27] Closing connection\n",
      "INFO:asyncssh:[conn=27, chan=0] Closing channel\n",
      "INFO:asyncssh:[conn=27] Sending disconnect: Disconnected by application (11)\n",
      "INFO:asyncssh:[conn=27] Connection closed\n",
      "INFO:asyncssh:[conn=27, chan=0] Closing channel due to connection close\n",
      "INFO:asyncssh:[conn=27, chan=0] Channel closed\n",
      "INFO:asyncssh:Opening SSH connection to github.com, port 22\n",
      "INFO:asyncssh:[conn=28] Connected to SSH server at github.com, port 22\n",
      "INFO:asyncssh:[conn=28]   Local address: 192.168.0.2, port 40620\n",
      "INFO:asyncssh:[conn=28]   Peer address: 140.82.114.3, port 22\n",
      "INFO:asyncssh:[conn=28] Beginning auth for user git\n",
      "INFO:asyncssh:[conn=28] Auth for user git succeeded\n",
      "INFO:asyncssh:[conn=28, chan=0] Requesting new SSH session\n",
      "INFO:asyncssh:[conn=28, chan=0]   Command: git-upload-pack '/junwang-wish/query_understanding_data.git'\n",
      "INFO:asyncssh:[conn=28] Closing connection\n",
      "INFO:asyncssh:[conn=28, chan=0] Closing channel\n",
      "INFO:asyncssh:[conn=28] Sending disconnect: Disconnected by application (11)\n",
      "INFO:asyncssh:[conn=28] Connection closed\n",
      "INFO:asyncssh:[conn=28, chan=0] Closing channel due to connection close\n",
      "INFO:asyncssh:[conn=28, chan=0] Channel closed\n",
      "INFO:asyncssh:Opening SSH connection to github.com, port 22\n",
      "INFO:asyncssh:[conn=29] Connected to SSH server at github.com, port 22\n",
      "INFO:asyncssh:[conn=29]   Local address: 192.168.0.2, port 59102\n",
      "INFO:asyncssh:[conn=29]   Peer address: 140.82.113.4, port 22\n",
      "INFO:asyncssh:[conn=29] Beginning auth for user git\n",
      "INFO:asyncssh:[conn=29] Auth for user git succeeded\n",
      "INFO:asyncssh:[conn=29, chan=0] Requesting new SSH session\n",
      "INFO:asyncssh:[conn=29, chan=0]   Command: git-upload-pack '/junwang-wish/query_understanding_data.git'\n",
      "INFO:asyncssh:[conn=29] Closing connection\n",
      "INFO:asyncssh:[conn=29, chan=0] Closing channel\n",
      "INFO:asyncssh:[conn=29] Sending disconnect: Disconnected by application (11)\n",
      "INFO:asyncssh:[conn=29] Connection closed\n",
      "INFO:asyncssh:[conn=29, chan=0] Closing channel due to connection close\n",
      "INFO:asyncssh:[conn=29, chan=0] Channel closed\n",
      "100%|██████████| 7/7 [01:16<00:00, 10.94s/it]\n"
     ]
    }
   ],
   "source": [
    "filtered_perms = []\n",
    "ind = -1\n",
    "for version in tqdm(version2inferfile):\n",
    "    ind += 1\n",
    "    if version.startswith('clm'):\n",
    "        infer_path = version2inferfile[version]\n",
    "        df_data, _ = get_df_outfile(dataset)\n",
    "        df_pred = read_json_helper(infer_path)\n",
    "        df_pred = df_pred[df_pred.rank_indices == 0].sort_values('batch_indices')\n",
    "        assert len(df_data) == len(df_pred)\n",
    "        df_data[f'{version}_predicted_category'] = df_pred['prediction_decoded'].tolist()\n",
    "        df_data[f'{version}_predicted_category'] = df_data[f'{version}_predicted_category'].apply(lambda x: x.split(' > '))\n",
    "        df_data = filter_data_func(df_data)\n",
    "        perm = pd.concat([perf_eval_util(df_data, level=i, col=f'{version}_predicted_category') for i in [1, 2, 0, -1, -2]])\n",
    "        perm['version'] = version\n",
    "        filtered_perms += perm[(perm.level == 1) & (perm['id'] == 'weighted avg')].to_dict('records')\n",
    "        if ind == 0:\n",
    "            perm_lance = pd.concat([perf_eval_util(df_data, level=i, col='lance_predicted_category') for i in [1, 2, 0, -1, -2]])\n",
    "            perm_lance['version'] = 'lance'\n",
    "            filtered_perms += perm_lance[(perm_lance.level == 1) & (perm_lance['id'] == 'weighted avg')].to_dict('records')\n",
    "    elif version.startswith('emb'):\n",
    "        infer_path_title = version2inferfile[version]\n",
    "        infer_path_tax = version2inferfile_tax[version]\n",
    "        df_data, _ = get_df_outfile(dataset) \n",
    "        df_pred = read_json_helper(infer_path_title) # title\n",
    "        df_pred = df_pred.sort_values('batch_indices')\n",
    "        assert len(df_data) == len(df_pred), f\"df_data {len(df_data)} df_pred {len(df_pred)}\"\n",
    "        df_pred_tax = read_json_helper(infer_path_tax) # tax\n",
    "        distance_func = version2distance_func[version]\n",
    "        df_data = perf_eval_util_emb(df_pred, df_pred_tax, df_data, version, distance_func)\n",
    "        df_data = filter_data_func(df_data)\n",
    "        perm = pd.concat([perf_eval_util(df_data, level=i, col=f'{version}_predicted_category') for i in [1, 2, 0, -1, -2]])\n",
    "        perm['version'] = version\n",
    "        filtered_perms += perm[(perm.level == 1) & (perm['id'] == 'weighted avg')].to_dict('records')\n",
    "    elif version.startswith('seqclf'):\n",
    "        infer_path = version2inferfile[version]\n",
    "        df_pred = read_json_helper(infer_path)\n",
    "        df_data, _ = get_df_outfile(dataset) \n",
    "        df_pred = df_pred.sort_values('batch_indices')\n",
    "        assert len(df_data) == len(df_pred), f\"df_data {len(df_data)} df_pred {len(df_pred)}\"\n",
    "        decode_method = version2decode_method[version]\n",
    "        df_data = perf_eval_utils_seqclf(df_pred, df_data, label_map_file, version, decode_method)\n",
    "        df_data = filter_data_func(df_data)\n",
    "        perm = pd.concat([perf_eval_util(df_data, level=i, col=f'{version}_predicted_category') for i in [1, 2, 0, -1, -2]])\n",
    "        perm['version'] = version\n",
    "        filtered_perms += perm[(perm.level == 1) & (perm['id'] == 'weighted avg')].to_dict('records')\n",
    "    else:\n",
    "        raise NotImplemented()\n",
    "df_filtered_perms = pd.DataFrame(filtered_perms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_perms.sort_values('version').to_csv('tmp_one_off_eval.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>level</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.817401</td>\n",
       "      <td>0.787657</td>\n",
       "      <td>0.791251</td>\n",
       "      <td>956.0</td>\n",
       "      <td>1</td>\n",
       "      <td>clm_v0.4_aliprompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.814522</td>\n",
       "      <td>0.783473</td>\n",
       "      <td>0.787064</td>\n",
       "      <td>956.0</td>\n",
       "      <td>1</td>\n",
       "      <td>clm_v0.4_wishprompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.803159</td>\n",
       "      <td>0.752092</td>\n",
       "      <td>0.749196</td>\n",
       "      <td>956.0</td>\n",
       "      <td>1</td>\n",
       "      <td>clm_v0.5_aliprompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.805846</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.745798</td>\n",
       "      <td>956.0</td>\n",
       "      <td>1</td>\n",
       "      <td>clm_v0.5_wishprompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.794184</td>\n",
       "      <td>0.769874</td>\n",
       "      <td>0.773274</td>\n",
       "      <td>956.0</td>\n",
       "      <td>1</td>\n",
       "      <td>emb_v0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.803957</td>\n",
       "      <td>0.778243</td>\n",
       "      <td>0.781252</td>\n",
       "      <td>956.0</td>\n",
       "      <td>1</td>\n",
       "      <td>emb_v0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.830450</td>\n",
       "      <td>0.811715</td>\n",
       "      <td>0.807202</td>\n",
       "      <td>956.0</td>\n",
       "      <td>1</td>\n",
       "      <td>lance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.827917</td>\n",
       "      <td>0.807531</td>\n",
       "      <td>0.807520</td>\n",
       "      <td>956.0</td>\n",
       "      <td>1</td>\n",
       "      <td>seqclf_v0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  precision    recall  f1-score  support  level  \\\n",
       "0  weighted avg   0.817401  0.787657  0.791251    956.0      1   \n",
       "2  weighted avg   0.814522  0.783473  0.787064    956.0      1   \n",
       "3  weighted avg   0.803159  0.752092  0.749196    956.0      1   \n",
       "4  weighted avg   0.805846  0.750000  0.745798    956.0      1   \n",
       "5  weighted avg   0.794184  0.769874  0.773274    956.0      1   \n",
       "6  weighted avg   0.803957  0.778243  0.781252    956.0      1   \n",
       "1  weighted avg   0.830450  0.811715  0.807202    956.0      1   \n",
       "7  weighted avg   0.827917  0.807531  0.807520    956.0      1   \n",
       "\n",
       "               version  \n",
       "0   clm_v0.4_aliprompt  \n",
       "2  clm_v0.4_wishprompt  \n",
       "3   clm_v0.5_aliprompt  \n",
       "4  clm_v0.5_wishprompt  \n",
       "5             emb_v0.0  \n",
       "6             emb_v0.4  \n",
       "1                lance  \n",
       "7          seqclf_v0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered_perms.sort_values('version')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ea19d11efa7602c1f12500925a974ed4f31fcf847bd6f694bd5180da2602ded"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
