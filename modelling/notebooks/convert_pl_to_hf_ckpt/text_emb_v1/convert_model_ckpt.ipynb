{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../../..')\n",
    "from main_multitask_multimodal import LLM_MultitaskMultimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Unused kwargs when getting hkunlp/instructor-base: {'distance_func': 'cosine', 'loss_type': 'cross-entropy', 'margin': None, 'hidden_states_type': 'encoder-mean', 'add_simcse': False, 'manual_loss_type': 'manual_mse', 'auto_task_weight': False, 'multitask_specs_dict': {'emb_singlemodal_wishquery2googletitle': None, 'seqclf_singlemodal_wishtitle2v121tax': {'specs': {'clf_head': 'clf_head_product', 'clf_weight_type': None, 'label_map_file': '/workspaces/multitask-llm-rnd/modelling/datasets/taxonomy/wish_v1.2.1_newtax_allpaths.txt', 'label_type': 'multilabel_taxonomy'}}, 'seqclf_singlemodal_wishquery2v121tax': {'specs': {'clf_head': 'clf_head_query', 'clf_weight_type': None, 'label_map_file': '/workspaces/multitask-llm-rnd/modelling/datasets/taxonomy/wish_v1.2.1_newtax_allpaths_withunknown.txt', 'label_type': 'multilabel_taxonomy'}}}, 'head_dict': {'clf_head_product': {'purpose': 'seqclf', 'type': 'linear', 'in_features': 768, 'out_features': 6037}, 'clf_head_query': {'purpose': 'seqclf', 'type': 'linear', 'in_features': 768, 'out_features': 6038}}}\n"
     ]
    }
   ],
   "source": [
    "model = LLM_MultitaskMultimodal.load_from_checkpoint('../../../models/product_query_textonly_multitask/version_2/epoch=0-step=800.ckpt'\n",
    "                                                     ).cuda().eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# qualitative check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = model.tokenizer([\n",
    "        \"Represent the E-commerce product title for retrieval: Big Dildo\",\n",
    "        \"Represent the E-commerce product title for retrieval: Milk\",\n",
    "        \"Represent the E-commerce product title for retrieval: Iphone\", \n",
    "        \"Represent the E-commerce product title for retrieval: Samsung\"\n",
    "    ], return_tensors='pt', padding=True, truncation=True, max_length=50).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_products = model.get_hidden_states(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = model.tokenizer([\n",
    "        \"Represent the E-commerce search query for retrieval: sex toy\",\n",
    "        \"Represent the E-commerce search query for retrieval: food\",\n",
    "        \"Represent the E-commerce search query for retrieval: electronics\", \n",
    "        \"Represent the E-commerce search query for retrieval: electronics apple\",\n",
    "        \"Represent the E-commerce search query for retrieval: electronics galaxy\"\n",
    "    ], return_tensors='pt', padding=True, truncation=True, max_length=50).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_query = model.get_hidden_states(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_query = nn.functional.normalize(embs_query)\n",
    "embs_products = nn.functional.normalize(embs_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3],\n",
       "       [1, 3, 2, 0],\n",
       "       [3, 2, 1, 0],\n",
       "       [2, 3, 1, 0],\n",
       "       [3, 2, 1, 0]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-embs_query.mm(embs_products.T).detach().cpu().numpy()).argsort(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: hkunlp/instructor-base\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "from InstructorEmbedding import INSTRUCTOR\n",
    "model2 = INSTRUCTOR('hkunlp/instructor-base')\n",
    "sentence = \"3D ActionSLAM: wearable person tracking in multi-floor environments\"\n",
    "instruction = \"Represent the E-commerce product title for retrieval:\"\n",
    "instruction2 = \"Represent the E-commerce search query for retrieval:\"\n",
    "embs_products = model2.encode([[instruction,sentence] for sentence in [\n",
    "    'Big Dildo', 'Milk', 'Iphone', 'Samsung'\n",
    "]])\n",
    "embs_query = model2.encode([[instruction,sentence] for sentence in [\n",
    "    'sex toy', 'food', 'electronics', 'electronics apple', 'electronics galaxy'\n",
    "]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 3, 2, 1],\n",
       "       [1, 3, 0, 2],\n",
       "       [3, 2, 0, 1],\n",
       "       [2, 3, 0, 1],\n",
       "       [3, 2, 0, 1]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-1 * embs_query.dot(embs_products.T)).argsort(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INSTRUCTOR(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: T5EncoderModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False})\n",
       "  (2): Dense({'in_features': 768, 'out_features': 768, 'bias': False, 'activation_function': 'torch.nn.modules.linear.Identity'})\n",
       "  (3): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5EncoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5TextEncoder(T5EncoderModel):\n",
    "    def forward(self,\n",
    "            input_ids = None,\n",
    "            attention_mask = None,\n",
    "            head_mask = None,\n",
    "            inputs_embeds = None,\n",
    "            output_attentions = None,\n",
    "            output_hidden_states = None,\n",
    "            return_dict = None):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        encoder_outputs = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            head_mask=head_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        token_embeddings = encoder_outputs.last_hidden_state\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        return sum_embeddings / sum_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hf = T5TextEncoder.from_pretrained('hkunlp/instructor-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hf.load_state_dict(model.transformer.state_dict(), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = model.tokenizer([\n",
    "        \"Represent the E-commerce search query for retrieval: sex toy\",\n",
    "        \"Represent the E-commerce search query for retrieval: food\",\n",
    "        \"Represent the E-commerce search query for retrieval: electronics\", \n",
    "        \"Represent the E-commerce search query for retrieval: electronics apple\",\n",
    "        \"Represent the E-commerce search query for retrieval: electronics galaxy\"\n",
    "    ], return_tensors='pt', padding=True, truncation=True, max_length=50).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1049,  1.1187, -0.0632,  ...,  0.3223,  0.1130, -0.2071],\n",
       "        [ 1.7254,  1.9041,  1.4327,  ..., -1.2619,  0.1200,  0.6428],\n",
       "        [-0.3199, -0.7741, -0.0882,  ..., -1.7333,  1.0926, -0.1274],\n",
       "        [-1.1760, -0.3870, -0.4076,  ..., -1.7242,  1.3544,  0.7890],\n",
       "        [ 0.1942,  1.4429, -1.4297,  ...,  0.4009,  0.1020, -1.1584]],\n",
       "       device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hf.eval().cuda()\n",
    "model_hf(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1049,  1.1187, -0.0632,  ...,  0.3223,  0.1130, -0.2071],\n",
       "        [ 1.7254,  1.9041,  1.4327,  ..., -1.2619,  0.1200,  0.6428],\n",
       "        [-0.3199, -0.7741, -0.0882,  ..., -1.7333,  1.0926, -0.1274],\n",
       "        [-1.1760, -0.3870, -0.4076,  ..., -1.7242,  1.3544,  0.7890],\n",
       "        [ 0.1942,  1.4429, -1.4297,  ...,  0.4009,  0.1020, -1.1584]],\n",
       "       device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval().cuda()\n",
    "model.get_hidden_states(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = inputs['input_ids']\n",
    "attention_mask = inputs['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONNX_PATH = f\"onnx_ckpt/model.onnx\"\n",
    "torch.onnx.export(\n",
    "    model_hf,\n",
    "    (input_ids, attention_mask),\n",
    "    ONNX_PATH,\n",
    "    input_names=[\"input_ids\", \"attention_mask\"],\n",
    "    output_names=[\"embs\"],\n",
    "    dynamic_axes={\n",
    "        'input_ids': {0: 'batch_size', 1: 'sequence_length'},\n",
    "        'attention_mask': {0: 'batch_size', 1: 'sequence_length'},\n",
    "        'embs': {0: 'batch_size'}\n",
    "    },\n",
    "    opset_version=13,\n",
    "    do_constant_folding=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "# Instantiate the ONNX Runtime session\n",
    "ort_session = ort.InferenceSession(ONNX_PATH)\n",
    "\n",
    "outputs = ort_session.run(\n",
    "    None,\n",
    "    {\n",
    "        \"input_ids\": input_ids.detach().cpu().numpy(),\n",
    "        \"attention_mask\": attention_mask.detach().cpu().numpy(),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.10488483,  1.1187394 , -0.06322645, ...,  0.3222735 ,\n",
       "          0.11304621, -0.2071243 ],\n",
       "        [ 1.725398  ,  1.9040842 ,  1.4327086 , ..., -1.2619073 ,\n",
       "          0.11998194,  0.64281094],\n",
       "        [-0.31993556, -0.7741432 , -0.08823031, ..., -1.7333367 ,\n",
       "          1.0925678 , -0.12737033],\n",
       "        [-1.175967  , -0.38696894, -0.40760002, ..., -1.7242362 ,\n",
       "          1.35442   ,  0.7889614 ],\n",
       "        [ 0.19422801,  1.4429021 , -1.4296671 , ...,  0.40093282,\n",
       "          0.10199822, -1.1584119 ]], dtype=float32)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ea19d11efa7602c1f12500925a974ed4f31fcf847bd6f694bd5180da2602ded"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
