{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'apparel accessories': 0, 'automobiles & motorcycles': 1, 'beauty & health': 2, 'cellphones & telecommunications': 3, 'computer & office': 4, 'consumer electronics': 5, 'education & office supplies': 6, 'electronic components & supplies': 7, 'entertainment': 8, 'food': 9, 'furniture': 10, 'hair extensions & wigs': 11, 'home & garden': 12, 'home improvement': 13, 'jewelry & accessories': 14, 'luggage & bags': 15, \"men's clothing\": 16, 'mother & kids': 17, 'novelty & special use': 18, 'security & protection': 19, 'shoes': 20, 'sports': 21, 'tools': 22, 'toys & hobbies': 23, 'virtual goods': 24, 'watches': 25, \"women's clothing\": 26, 'unknown': 27}\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.classification import (\n",
    "    MultiLabelClassificationModel, MultiLabelClassificationArgs\n",
    ")\n",
    "import pandas as pd\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "# %%\n",
    "import dvc.api\n",
    "\n",
    "df_test = pd.read_json(dvc.api.get_url(\n",
    "    'datasets/data/query_label/processed/Offshore_Labelled_Query_Classification_Test_V2.json',\n",
    "    repo='git@github.com:ContextLogic/multitask-llm-rnd.git'\n",
    "), lines=True)\n",
    "\n",
    "# %%\n",
    "df_tax = pd.read_json(dvc.api.get_url(\n",
    "    'datasets/data/taxonomy/wish_newtax.json',\n",
    "    repo='git@github.com:ContextLogic/multitask-llm-rnd.git'\n",
    "), lines=True)\n",
    "df_tax = df_tax[(df_tax.category_path.apply(len) > 0) & (df_tax.category_path.apply(lambda x: len(x.split(' > ')) == 1))]\n",
    "\n",
    "# %%\n",
    "LABEL_SET = sorted(df_tax.category_path.str.lower().str.strip().tolist()) + ['unknown']\n",
    "\n",
    "# %%\n",
    "LABEL_NAME_TO_ID = {i: ind for ind, i in enumerate(LABEL_SET)}\n",
    "print(LABEL_NAME_TO_ID)\n",
    "# %%\n",
    "\n",
    "# %%\n",
    "def categories2labels(cats):\n",
    "    if len(cats) == 0:\n",
    "        cats = ['unknown']\n",
    "    labs = [0] * len(LABEL_NAME_TO_ID)\n",
    "    for c in cats:\n",
    "        labs[LABEL_NAME_TO_ID[c]] = 1\n",
    "    return labs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiLabelClassificationModel(\n",
    "    \"xlmroberta\",\n",
    "    \"outputs/best_model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['labels'] = df_test['query_classification_lists'].apply(\n",
    "    lambda x: categories2labels([i.lower().strip().split(' > ')[0] for i in x]))\n",
    "df_test['text'] = df_test['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81777d2edb11492cb5f982cc914baeea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/1681 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result, model_outputs, wrong_predictions = model.eval_model(\n",
    "    df_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LRAP': 0.8539614235731265, 'eval_loss': 0.07486113636911797}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LRAP': 0.8318010818326117, 'eval_loss': 0.08628105077280894}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(np.array(df_test['labels'].tolist()), model_outputs>.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qcv2 = pd.read_json(\n",
    "    \"../../models/multitask_multimodal_multilingual/version_9/clm-epoch=1-step=2600--wish_labelled_query_offshore_test_V2--test.json\", \n",
    "    lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qcv2 = df_qcv2.sort_values(['batch_indices', 'rank_indices']).groupby('batch_indices').agg({\n",
    "    'prediction_decoded': lambda x: [i for i in x], \n",
    "    'prob': lambda x: [i for i in x]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13448"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = []\n",
    "for i in df_qcv2.to_dict('records'):\n",
    "    prediction_decoded_confident = []\n",
    "    for pred, prob in zip(i['prediction_decoded'], i['prob']):\n",
    "        if prob >= .05:\n",
    "            prediction_decoded_confident.append(pred)\n",
    "    i['prediction_decoded_confident'] = prediction_decoded_confident\n",
    "    recs.append(i)\n",
    "df_qcv2 = pd.DataFrame(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df_qcv2['labels'] = df_qcv2['prediction_decoded_confident'].apply(\n",
    "    lambda x: categories2labels([i.lower().strip().split(' > ')[0] for i in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(np.array(df_test['labels'].tolist()), np.array(df_qcv2['labels'].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ea19d11efa7602c1f12500925a974ed4f31fcf847bd6f694bd5180da2602ded"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
