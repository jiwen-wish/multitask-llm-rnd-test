{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_inference_multimodal import LLM_Inference_Multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open '/workspaces/multitask-llm-rnd/data/datasets/taxonomy/wish_v1.2.1_newtax_allpaths.txt' for reading: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!head /workspaces/multitask-llm-rnd/data/datasets/taxonomy/wish_v1.2.1_newtax_allpaths.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Unused kwargs when getting google/mt5-base: {'distance_func': 'cosine', 'loss_type': 'cross-entropy', 'margin': None, 'hidden_states_type': 'encoder-last', 'add_simcse': False, 'manual_loss_type': 'manual_mse', 'auto_task_weight': False, 'multitask_specs_dict': {'clm_singlemodal_wishquery2tax': None}, 'head_dict': {}}\n",
      "/opt/conda/envs/py38/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/py38/lib/python3.8/site-packages/pytorch_lightning/core/saving.py:263: UserWarning: Found keys that are in the model state dict but not in the checkpoint: ['transformer.encoder.embed_tokens.weight', 'transformer.decoder.embed_tokens.weight']\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "model = LLM_Inference_Multimodal(\n",
    "    llm_type='clm', \n",
    "    ckpt_path='/workspaces/multitask-llm-rnd/modelling/models/multitask_multimodal_multilingual/version_9_simplecopy/pytorch_model.bin',\n",
    "    config_path='/workspaces/multitask-llm-rnd/modelling/models/multitask_multimodal_multilingual/version_9_simplecopy/config.yaml', \n",
    "    task='clm_singlemodal_wishquery2tax',\n",
    "    allowed_gen_sequences='/workspaces/multitask-llm-rnd/modelling/datasets/taxonomy/wish_v1.2.1_newtax_allpaths.txt',\n",
    "    num_beams=3, \n",
    "    num_return_sequences=3,\n",
    "    do_sample=False,\n",
    "    length_penalty=0,\n",
    "    max_new_tokens=50,\n",
    "    output_dir='tmp',\n",
    ")\n",
    "\n",
    "# .load_from_checkpoint('/workspaces/multitask-llm-rnd/modelling/models/multitask_multimodal_multilingual/version_9_simplecopy/pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad> cellphones & telecommunications > cellphones</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<pad> cellphones & telecommunications > iphones</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<pad> cellphones & telecommunications > mobile phone accessories</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model.llm.tokenizer.batch_decode(\n",
    "    model.forward(\n",
    "        model.llm.tokenizer('Generate taxonomy for query: phones', return_tensors='pt')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_queries = [ \n",
    "    'car',\n",
    "    'dragon ball z',\n",
    "    'phones'\n",
    "]\n",
    "with open('tmp.json', 'w') as f:\n",
    "    for q in bad_queries:\n",
    "        f.write(json.dumps({'query': q}) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_queries = [ \n",
    "    'car',\n",
    "    'dragon ball z',\n",
    "    'phones'\n",
    "]\n",
    "with open('tmp.json', 'w') as f:\n",
    "    for q in bad_queries:\n",
    "        f.write(json.dumps({'query': q}) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python main_inference_multimodal.py \\\n",
    "#         --model=LLM_Inference_Multimodal \\\n",
    "#         --model.llm_type=\"clm\" \\\n",
    "#         --model.output_scores=true \\\n",
    "#         --model.ckpt_path=\"/workspaces/multitask-llm-rnd/modelling/models/multitask_multimodal_multilingual/version_9_simplecopy/pytorch_model.bin\" \\\n",
    "#         --model.config_path=\"/workspaces/multitask-llm-rnd/modelling/models/multitask_multimodal_multilingual/version_9_simplecopy/config.yaml\" \\\n",
    "#         --model.task=\"clm_singlemodal_wishquery2tax\" \\\n",
    "#         --model.allowed_gen_sequences=\"/workspaces/multitask-llm-rnd/modelling/datasets/taxonomy/wish_v1.2.1_newtax_allpaths.txt\" \\\n",
    "#         --model.num_beams=3 \\\n",
    "#         --model.num_return_sequences=3 \\\n",
    "#         --model.length_penalty=0 \\\n",
    "#         --model.do_sample=false \\\n",
    "#         --model.max_new_tokens=50 \\\n",
    "#         --model.output_dir=\"/workspaces/multitask-llm-rnd/modelling/notebooks/model\" \\\n",
    "#         --model.write_interval=\"batch\" \\\n",
    "#         --data=JSONListData \\\n",
    "#         --data.llm_type=\"clm\" \\\n",
    "#         --data.data_source_yaml_path=\"/workspaces/multitask-llm-rnd/modelling/notebooks/model/tmp.yaml\" \\\n",
    "#         --data.input_dict=\"{'template': '{query}', 'task_prefix': 'Generate taxonomy for query: '}\" \\\n",
    "#         --data.output_dict=\"{'template': '{query}'}\" \\\n",
    "#         --data.data_source_type=\"local\" \\\n",
    "#         --data.model_name=\"google/mt5-base\" \\\n",
    "#         --data.batch_size=1 \\\n",
    "#         --data.max_length=50 \\\n",
    "#         --data.num_workers=0 \\\n",
    "#         --data.max_length_out=50 \\\n",
    "#         --data.overwrite_cache=true \\\n",
    "#         --data.force_download_hfdata=true \\\n",
    "#         --trainer.logger=false \\\n",
    "#         --trainer.enable_checkpointing=false"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ea19d11efa7602c1f12500925a974ed4f31fcf847bd6f694bd5180da2602ded"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
