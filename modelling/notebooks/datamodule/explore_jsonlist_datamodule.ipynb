{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath = '/workspaces/multitask-llm-rnd/modelling/datasets/demo_local/tmp_multimodal_data.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>image_embedding</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>product_0</td>\n",
       "      <td>description_0</td>\n",
       "      <td>[0.171962763952969, 0.5508460593498861, 0.7762...</td>\n",
       "      <td>[baby, food]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product_1</td>\n",
       "      <td>description_1</td>\n",
       "      <td>[0.418064474399429, 0.18682814017889202, 0.520...</td>\n",
       "      <td>[baby, food]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>product_2</td>\n",
       "      <td>description_2</td>\n",
       "      <td>[0.31318309646164505, 0.8549012641982541, 0.48...</td>\n",
       "      <td>[baby, food]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>product_3</td>\n",
       "      <td>description_3</td>\n",
       "      <td>[0.117538370586533, 0.46330634025660405, 0.953...</td>\n",
       "      <td>[baby, food]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>product_4</td>\n",
       "      <td>description_4</td>\n",
       "      <td>[0.48497709804257805, 0.5759276845722421, 0.96...</td>\n",
       "      <td>[baby, food]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title    description  \\\n",
       "0  product_0  description_0   \n",
       "1  product_1  description_1   \n",
       "2  product_2  description_2   \n",
       "3  product_3  description_3   \n",
       "4  product_4  description_4   \n",
       "\n",
       "                                     image_embedding      category  \n",
       "0  [0.171962763952969, 0.5508460593498861, 0.7762...  [baby, food]  \n",
       "1  [0.418064474399429, 0.18682814017889202, 0.520...  [baby, food]  \n",
       "2  [0.31318309646164505, 0.8549012641982541, 0.48...  [baby, food]  \n",
       "3  [0.117538370586533, 0.46330634025660405, 0.953...  [baby, food]  \n",
       "4  [0.48497709804257805, 0.5759276845722421, 0.96...  [baby, food]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json(\n",
    "    dpath,\n",
    "    lines=True\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath = '/workspaces/multitask-llm-rnd/modelling/datasets/demo_local/tmp_multimodal_full_data.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>img_embedding</th>\n",
       "      <th>category</th>\n",
       "      <th>pseudo_category</th>\n",
       "      <th>relevance</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>product_0 a really nice product</td>\n",
       "      <td>description_0 a really nice description</td>\n",
       "      <td>[0.015897007550838, 0.6816330348703731, 0.3409...</td>\n",
       "      <td>[bAbY, fOod]</td>\n",
       "      <td>[baBy, dRinks]</td>\n",
       "      <td>0.499575</td>\n",
       "      <td>query_0 a really nice query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product_1 a really nice product</td>\n",
       "      <td>description_1 a really nice description</td>\n",
       "      <td>[0.8479370084425091, 0.207535229189333, 0.4766...</td>\n",
       "      <td>[bAbY, fOod]</td>\n",
       "      <td>[baBy, dRinks]</td>\n",
       "      <td>0.988359</td>\n",
       "      <td>query_1 a really nice query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>product_2 a really nice product</td>\n",
       "      <td>description_2 a really nice description</td>\n",
       "      <td>[0.041579119160669004, 0.890535048384234, 0.91...</td>\n",
       "      <td>[bAbY, fOod]</td>\n",
       "      <td>[baBy, dRinks]</td>\n",
       "      <td>0.558101</td>\n",
       "      <td>query_2 a really nice query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>product_3 a really nice product</td>\n",
       "      <td>description_3 a really nice description</td>\n",
       "      <td>[0.60815373754961, 0.33499207652104, 0.9978104...</td>\n",
       "      <td>[bAbY, fOod]</td>\n",
       "      <td>[baBy, dRinks]</td>\n",
       "      <td>0.013519</td>\n",
       "      <td>query_3 a really nice query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>product_4 a really nice product</td>\n",
       "      <td>description_4 a really nice description</td>\n",
       "      <td>[0.26445276824080804, 0.28299262430495703, 0.4...</td>\n",
       "      <td>[bAbY, fOod]</td>\n",
       "      <td>[baBy, dRinks]</td>\n",
       "      <td>0.896922</td>\n",
       "      <td>query_4 a really nice query</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title                              description  \\\n",
       "0  product_0 a really nice product  description_0 a really nice description   \n",
       "1  product_1 a really nice product  description_1 a really nice description   \n",
       "2  product_2 a really nice product  description_2 a really nice description   \n",
       "3  product_3 a really nice product  description_3 a really nice description   \n",
       "4  product_4 a really nice product  description_4 a really nice description   \n",
       "\n",
       "                                       img_embedding      category  \\\n",
       "0  [0.015897007550838, 0.6816330348703731, 0.3409...  [bAbY, fOod]   \n",
       "1  [0.8479370084425091, 0.207535229189333, 0.4766...  [bAbY, fOod]   \n",
       "2  [0.041579119160669004, 0.890535048384234, 0.91...  [bAbY, fOod]   \n",
       "3  [0.60815373754961, 0.33499207652104, 0.9978104...  [bAbY, fOod]   \n",
       "4  [0.26445276824080804, 0.28299262430495703, 0.4...  [bAbY, fOod]   \n",
       "\n",
       "  pseudo_category  relevance                        query  \n",
       "0  [baBy, dRinks]   0.499575  query_0 a really nice query  \n",
       "1  [baBy, dRinks]   0.988359  query_1 a really nice query  \n",
       "2  [baBy, dRinks]   0.558101  query_2 a really nice query  \n",
       "3  [baBy, dRinks]   0.013519  query_3 a really nice query  \n",
       "4  [baBy, dRinks]   0.896922  query_4 a really nice query  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json(\n",
    "    dpath,\n",
    "    lines=True\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_utils_multimodal import JSONListData, Dataset, LLM_MultitaskMultiModalData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# arbitrary jsonlist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Unused kwargs when getting t5-base: {}\n",
      "/opt/conda/envs/py38/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "INFO:root:loading /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml from local\n",
      "INFO:root:Write predict.json.gz to /data/junwang/.cache/general/6c567415c26cb7620fb8c8373a4ef972\n",
      "INFO:root:Download local /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/tmp_multimodal_data.json from /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml now...\n",
      "0it [00:00, ?it/s]WARNING:root:baby > food not in label_map, matched to ('food', 90)\n",
      "WARNING:root:match_label_map grow to 1\n",
      "1000it [00:01, 779.20it/s]\n",
      "INFO:root:Successfully write predict.json.gz to /data/junwang/.cache/general/6c567415c26cb7620fb8c8373a4ef972\n",
      "INFO:root:Write test.json.gz to /data/junwang/.cache/general/6c567415c26cb7620fb8c8373a4ef972\n",
      "INFO:root:Download local /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/tmp_multimodal_data.json from /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml now...\n",
      "1000it [00:00, 1441.45it/s]\n",
      "INFO:root:Successfully write test.json.gz to /data/junwang/.cache/general/6c567415c26cb7620fb8c8373a4ef972\n",
      "INFO:root:Write train.json.gz to /data/junwang/.cache/general/6c567415c26cb7620fb8c8373a4ef972\n",
      "INFO:root:Download local /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/tmp_multimodal_data.json from /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml now...\n",
      "1000it [00:00, 1569.21it/s]\n",
      "INFO:root:Successfully write train.json.gz to /data/junwang/.cache/general/6c567415c26cb7620fb8c8373a4ef972\n",
      "INFO:root:Write val.json.gz to /data/junwang/.cache/general/6c567415c26cb7620fb8c8373a4ef972\n",
      "INFO:root:Download local /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/tmp_multimodal_data.json from /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml now...\n",
      "1000it [00:00, 1476.69it/s]\n",
      "INFO:root:Successfully write val.json.gz to /data/junwang/.cache/general/6c567415c26cb7620fb8c8373a4ef972\n",
      "INFO:root:Convert data in /data/junwang/.cache/general/6c567415c26cb7620fb8c8373a4ef972 to Huggingface dataset\n",
      "WARNING:datasets.builder:Using custom data configuration default-e503b12711d6c137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /data/junwang/.cache/huggingface/datasets/json/default-e503b12711d6c137/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb9f116fbc3438bba720944301f078f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35495502b3d24ce9a1670d8ce4e520a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52b8f1db01f94edeb981f9abd5fb512b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /data/junwang/.cache/huggingface/datasets/json/default-e503b12711d6c137/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-5d9263d1fbf06ff3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /data/junwang/.cache/huggingface/datasets/json/default-5d9263d1fbf06ff3/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1dc8ed53c14e1d967549b61275d270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c987292c667d431ca11f0a2ac0ce29f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35826a5477494379802ac72fecc07bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /data/junwang/.cache/huggingface/datasets/json/default-5d9263d1fbf06ff3/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-9fc6d205aa758952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /data/junwang/.cache/huggingface/datasets/json/default-9fc6d205aa758952/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f3c9411347244e6835ada78fa1d1b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd573a2709b42aebbcbc7d8aa140860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35406ce560fd4f5795f8b307ab6b348c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /data/junwang/.cache/huggingface/datasets/json/default-9fc6d205aa758952/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-3d8d92b353676b93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /data/junwang/.cache/huggingface/datasets/json/default-3d8d92b353676b93/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d65f1d8d8c4ab6b896293c3dacbb7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e7b41a2d92b454b8c2facf6ce90f3d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57146b9636764568862fc0f52d7770ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /data/junwang/.cache/huggingface/datasets/json/default-3d8d92b353676b93/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:hf dataset: DatasetDict({\n",
      "    predict: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Tensor shapes:  {'input_ids': torch.Size([2, 50]), 'attention_mask': torch.Size([2, 50]), 'labels': torch.Size([2, 6037]), 'input_multimodal_embedding_0': torch.Size([2, 100])} \n",
      "\n",
      "> Input toks:  ['Classify product with image: [title start] product_0 [title end] [image start]<extra_id_99> [image end]</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', 'Classify product with image: [title start] product_1 [title end] [image start]<extra_id_99> [image end]</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'] \n",
      "\n",
      "> Output labs:  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for multimodal seqclf (taxonomy classification)\n",
    "data = JSONListData(**{\n",
    "    \"data_source_yaml_path\": \"/workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml\",\n",
    "    \"label_map_file\": \"/workspaces/multitask-llm-rnd/modelling/datasets/taxonomy/wish_v1.2.1_newtax_allpaths.txt\",\n",
    "    \"label_type\": \"taxonomy\", \n",
    "    \"llm_type\": \"seqclf\",\n",
    "    \"input_dict\": {\n",
    "        \"template\": (\"[title start] {title} [title end] \"\n",
    "            \"[image start] {image_embedding} [image end]\"),\n",
    "        \"task_prefix\": \"Classify product with image: \",\n",
    "        \"is_multimodal_embedding\": [\"image_embedding\"]\n",
    "    },\n",
    "    \"output_dict\": {\n",
    "        \"template\": \"{category}\"\n",
    "    },\n",
    "    \"data_source_type\": \"local\",\n",
    "    \"transform_dict\": {\n",
    "        \"category\": \"taxonomy\"\n",
    "    },\n",
    "    \"overwrite_cache\": True\n",
    "})\n",
    "data.prepare_data()\n",
    "data.setup('predict')\n",
    "batch = data.ds['predict'][:2]\n",
    "print(\"> Tensor shapes: \", {i: batch[i].shape for i in batch}, '\\n')\n",
    "print(\"> Input toks: \", data.tokenizer.batch_decode(batch['input_ids']), '\\n')\n",
    "tmp = batch['labels']\n",
    "print(\"> Output labs: \", tmp, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Unused kwargs when getting t5-base: {}\n",
      "/opt/conda/envs/py38/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "INFO:root:loading /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml from local\n",
      "INFO:root:Write predict.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Download local /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/tmp_multimodal_data.json from /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml now...\n",
      "1000it [00:00, 1563.23it/s]\n",
      "INFO:root:Successfully write predict.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Write test.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Download local /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/tmp_multimodal_data.json from /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml now...\n",
      "1000it [00:00, 1779.03it/s]\n",
      "INFO:root:Successfully write test.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Write train.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Download local /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/tmp_multimodal_data.json from /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml now...\n",
      "1000it [00:00, 1492.26it/s]\n",
      "INFO:root:Successfully write train.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Write val.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Download local /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/tmp_multimodal_data.json from /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml now...\n",
      "1000it [00:00, 1558.94it/s]\n",
      "INFO:root:Successfully write val.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Convert data in /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c to Huggingface dataset\n",
      "WARNING:datasets.builder:Using custom data configuration default-615544b0ca2fdd4c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /data/junwang/.cache/huggingface/datasets/json/default-615544b0ca2fdd4c/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5afaafaf64494625b983b860141b89ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc12f7460ecc4303ae9df2e2dc98501d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b169dba74e44ea6923ba27c991e9166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /data/junwang/.cache/huggingface/datasets/json/default-615544b0ca2fdd4c/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-b9539f9619677edc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /data/junwang/.cache/huggingface/datasets/json/default-b9539f9619677edc/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b600589cb48b479db2bad908ea34e15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15551bb64bf94af8831767270d807b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1724dfb0044b92bc6191b16a923b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /data/junwang/.cache/huggingface/datasets/json/default-b9539f9619677edc/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-8686d13964eae31a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /data/junwang/.cache/huggingface/datasets/json/default-8686d13964eae31a/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f653f57ea243f98f8e8b685eae2a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b14ef1168104c31a389267654fe0d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6129b4c2ce224e779a5dace1ff24630e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /data/junwang/.cache/huggingface/datasets/json/default-8686d13964eae31a/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-c44e8796ad8e14d0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /data/junwang/.cache/huggingface/datasets/json/default-c44e8796ad8e14d0/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929245d7a8204cff8b6be82202fa89fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc971c09b2f847e0a803d98633a0bbc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0dd7d854b54029a0c1607fa54ff27b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /data/junwang/.cache/huggingface/datasets/json/default-c44e8796ad8e14d0/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:hf dataset: DatasetDict({\n",
      "    predict: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Tensor shapes:  {'input_ids': torch.Size([2, 50]), 'attention_mask': torch.Size([2, 50]), 'labels': torch.Size([2, 50]), 'input_multimodal_embedding_0': torch.Size([2, 100])} \n",
      "\n",
      "> Input toks:  ['Top-down categorize product with image: [title start] product_0 [title end] [image start]<extra_id_99> [image end]</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', 'Top-down categorize product with image: [title start] product_1 [title end] [image start]<extra_id_99> [image end]</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'] \n",
      "\n",
      "> Output toks:  ['baby > food</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', 'baby > food</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for multimodal clm (taxonomy generation)\n",
    "data = JSONListData(**{\n",
    "    \"llm_type\": \"clm\",\n",
    "    \"data_source_yaml_path\": \"/workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml\",\n",
    "    \"input_dict\": {\n",
    "            \"template\": (\"[title start] {title} [title end] \"\n",
    "                \"[image start] {image_embedding} [image end]\"),\n",
    "            \"task_prefix\": \"Top-down categorize product with image: \",\n",
    "            \"is_multimodal_embedding\": [\"image_embedding\"]\n",
    "        },\n",
    "    \"output_dict\": {\n",
    "        \"template\": \"{category}\"\n",
    "    },\n",
    "    \"data_source_type\": \"local\",\n",
    "    \"transform_dict\": {\n",
    "        \"category\": \"taxonomy\"\n",
    "    },\n",
    "    \"overwrite_cache\": True\n",
    "})\n",
    "data.prepare_data()\n",
    "data.setup('predict')\n",
    "batch = data.ds['predict'][:2]\n",
    "print(\"> Tensor shapes: \", {i: batch[i].shape for i in batch}, '\\n')\n",
    "print(\"> Input toks: \", data.tokenizer.batch_decode(batch['input_ids']), '\\n')\n",
    "tmp = batch['labels']\n",
    "tmp[tmp==-100] = 0\n",
    "print(\"> Output toks: \", data.tokenizer.batch_decode(tmp), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Unused kwargs when getting t5-base: {}\n",
      "INFO:root:loading /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml from local\n",
      "INFO:root:Write predict.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Download local /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/tmp_multimodal_data.json from /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml now...\n",
      "1000it [00:00, 1722.35it/s]\n",
      "INFO:root:Successfully write predict.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Write test.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Download local /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/tmp_multimodal_data.json from /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml now...\n",
      "1000it [00:00, 1528.65it/s]\n",
      "INFO:root:Successfully write test.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Write train.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Download local /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/tmp_multimodal_data.json from /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml now...\n",
      "1000it [00:00, 1494.59it/s]\n",
      "INFO:root:Successfully write train.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Write val.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Download local /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/tmp_multimodal_data.json from /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml now...\n",
      "1000it [00:00, 1675.42it/s]\n",
      "INFO:root:Successfully write val.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Convert data in /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c to Huggingface dataset\n",
      "WARNING:datasets.builder:Using custom data configuration default-2c734dffb92ce7f9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /data/junwang/.cache/huggingface/datasets/json/default-2c734dffb92ce7f9/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ba26394ba843e6b47abf59cc2b3536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c4a9deb08e40f6a3dec003875ba7fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21e04f59e644195bbd74afcb5c084de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /data/junwang/.cache/huggingface/datasets/json/default-2c734dffb92ce7f9/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-f0337bdd51cf30e4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /data/junwang/.cache/huggingface/datasets/json/default-f0337bdd51cf30e4/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac72bd42d624ef2a9770201d36a3bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d11830717ad4e5d896011ba673cc0af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ff4178f0be4721ab53a02153e6da9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /data/junwang/.cache/huggingface/datasets/json/default-f0337bdd51cf30e4/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-7f0cf4750e1839a1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /data/junwang/.cache/huggingface/datasets/json/default-7f0cf4750e1839a1/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97395f04ab04d03a7b0ca3350aede4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9dde61fa254e85ae6c53b07a51ae68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0039c5d61474227a6f0e0772b6db623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /data/junwang/.cache/huggingface/datasets/json/default-7f0cf4750e1839a1/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-398783b8942c42e9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /data/junwang/.cache/huggingface/datasets/json/default-398783b8942c42e9/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6429548551f4feea79c0437c0463484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c37b8234fc74aabaa7aa783953762ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04efcb9ac0cc42589a4f0d1c58443a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /data/junwang/.cache/huggingface/datasets/json/default-398783b8942c42e9/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:hf dataset: DatasetDict({\n",
      "    predict: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Tensor shapes:  {'input_ids': torch.Size([2, 50]), 'attention_mask': torch.Size([2, 50]), 'labels': torch.Size([2, 50]), 'input_multimodal_embedding_0': torch.Size([2, 100])} \n",
      "\n",
      "> Input toks:  ['Generate title for product with image: [image start]<extra_id_99> [image end]</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', 'Generate title for product with image: [image start]<extra_id_99> [image end]</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'] \n",
      "\n",
      "> Output toks:  ['product_0</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', 'product_1</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for multimodal clm (title generation)\n",
    "data = JSONListData(**{\n",
    "    \"llm_type\": \"clm\",\n",
    "    \"data_source_yaml_path\": \"/workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml\",\n",
    "    \"input_dict\": {\n",
    "            \"template\": \"[image start] {image_embedding} [image end]\",\n",
    "            \"task_prefix\": \"Generate title for product with image: \",\n",
    "            \"is_multimodal_embedding\": [\"image_embedding\"]\n",
    "        },\n",
    "    \"output_dict\": {\n",
    "        \"template\": \"{title}\"\n",
    "    },\n",
    "    \"data_source_type\": \"local\",\n",
    "    \"transform_dict\": {\n",
    "        \"category\": \"taxonomy\"\n",
    "    },\n",
    "    \"overwrite_cache\": True\n",
    "})\n",
    "data.prepare_data()\n",
    "data.setup('predict')\n",
    "batch = data.ds['predict'][:2]\n",
    "print(\"> Tensor shapes: \", {i: batch[i].shape for i in batch}, '\\n')\n",
    "print(\"> Input toks: \", data.tokenizer.batch_decode(batch['input_ids']), '\\n')\n",
    "tmp = batch['labels']\n",
    "tmp[tmp==-100] = 0\n",
    "print(\"> Output toks: \", data.tokenizer.batch_decode(tmp), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Unused kwargs when getting t5-base: {}\n",
      "INFO:root:loading /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml from local\n",
      "INFO:root:Write predict.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Download local /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/tmp_multimodal_data.json from /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml now...\n",
      "1000it [00:00, 1750.94it/s]\n",
      "INFO:root:Successfully write predict.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Write test.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Download local /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/tmp_multimodal_data.json from /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml now...\n",
      "1000it [00:00, 1566.48it/s]\n",
      "INFO:root:Successfully write test.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Write train.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Download local /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/tmp_multimodal_data.json from /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml now...\n",
      "1000it [00:00, 1686.26it/s]\n",
      "INFO:root:Successfully write train.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Write val.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Download local /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/tmp_multimodal_data.json from /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml now...\n",
      "1000it [00:00, 1666.32it/s]\n",
      "INFO:root:Successfully write val.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Convert data in /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c to Huggingface dataset\n",
      "WARNING:datasets.builder:Using custom data configuration default-1e83d8b3c7457b00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /data/junwang/.cache/huggingface/datasets/json/default-1e83d8b3c7457b00/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763d5ae66bfb4c418cce462316c512cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f76054205ef42309bd22a5755b1d155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2012df64db9f42b0bcde3979722eb2d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /data/junwang/.cache/huggingface/datasets/json/default-1e83d8b3c7457b00/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-11a13d6713f8e603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /data/junwang/.cache/huggingface/datasets/json/default-11a13d6713f8e603/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d720b5c41b8d4a079edc370b8bd26020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c518105d01164cae9c7b9140a5387b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb37882e41b040a09550a9d6338b0c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /data/junwang/.cache/huggingface/datasets/json/default-11a13d6713f8e603/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-cf635ad4a308f437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /data/junwang/.cache/huggingface/datasets/json/default-cf635ad4a308f437/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "895547f42b094d9f9739d83a6100de74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d81bf38d554845eab4ef1a870c303271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec7973a25824561bc08b063d033e9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /data/junwang/.cache/huggingface/datasets/json/default-cf635ad4a308f437/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-c811d6adea8379b3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /data/junwang/.cache/huggingface/datasets/json/default-c811d6adea8379b3/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b122adab0e4285a7c25b1457f08bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d7f054199e4f27a66831730858e642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd16f91c09f4835980e83ae4257cef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /data/junwang/.cache/huggingface/datasets/json/default-c811d6adea8379b3/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:hf dataset: DatasetDict({\n",
      "    predict: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Tensor shapes:  {'input_ids': torch.Size([2, 50]), 'attention_mask': torch.Size([2, 50]), 'labels': torch.Size([2, 50]), 'input_multimodal_embedding_0': torch.Size([2, 100])} \n",
      "\n",
      "> Input toks:  ['Denoise product with image: [title start] p<extra_id_0> oduc<extra_id_1> _0 [title end] [image start]<extra_id_99> [image end]</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', 'Denoise product with image: [title start] p<extra_id_0> odu<extra_id_1> t_1 [title end] [image start]<extra_id_99> [image end]</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'] \n",
      "\n",
      "> Output toks:  ['<extra_id_0> r<extra_id_1> t<extra_id_2></s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', '<extra_id_0> r<extra_id_1> c<extra_id_2></s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for multimodal dlm (title denoising)\n",
    "data = JSONListData(**{\n",
    "    \"llm_type\": \"dlm\",\n",
    "    \"data_source_yaml_path\": \"/workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml\",\n",
    "    \"input_dict\": {\n",
    "        \"template\": (\"[title start] {title} [title end] \"\n",
    "            \"[image start] {image_embedding} [image end]\"),\n",
    "        \"task_prefix\": \"Denoise product with image: \",\n",
    "        \"is_multimodal_embedding\": [\"image_embedding\"]\n",
    "    },\n",
    "    \"output_dict\": {\n",
    "        \"template\": \"{title}\"\n",
    "    },\n",
    "    \"data_source_type\": \"local\",\n",
    "    \"transform_dict\": {\n",
    "        \"category\": \"taxonomy\"\n",
    "    },\n",
    "    \"overwrite_cache\": True\n",
    "})\n",
    "data.prepare_data()\n",
    "data.setup('predict')\n",
    "batch = data.ds['predict'][:2]\n",
    "print(\"> Tensor shapes: \", {i: batch[i].shape for i in batch}, '\\n')\n",
    "print(\"> Input toks: \", data.tokenizer.batch_decode(batch['input_ids']), '\\n')\n",
    "tmp = batch['labels']\n",
    "tmp[tmp==-100] = 0\n",
    "print(\"> Output toks: \", data.tokenizer.batch_decode(tmp), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Unused kwargs when getting t5-base: {}\n",
      "INFO:root:loading /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml from local\n",
      "INFO:root:Write predict.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Download local /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/tmp_multimodal_data.json from /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml now...\n",
      "1000it [00:00, 1534.13it/s]\n",
      "INFO:root:Successfully write predict.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Write test.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Download local /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/tmp_multimodal_data.json from /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml now...\n",
      "1000it [00:00, 1554.14it/s]\n",
      "INFO:root:Successfully write test.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Write train.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Download local /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/tmp_multimodal_data.json from /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml now...\n",
      "1000it [00:00, 1575.08it/s]\n",
      "INFO:root:Successfully write train.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Write val.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Download local /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/tmp_multimodal_data.json from /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml now...\n",
      "1000it [00:00, 1712.06it/s]\n",
      "INFO:root:Successfully write val.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Convert data in /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c to Huggingface dataset\n",
      "WARNING:datasets.builder:Using custom data configuration default-4b4f3e8cc987c9e0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /data/junwang/.cache/huggingface/datasets/json/default-4b4f3e8cc987c9e0/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b756cf6b884127b78e504a238a11dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7154c08e76a465d86a84465c5299663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695f6752138b4b3abf9c7f9b8a630f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /data/junwang/.cache/huggingface/datasets/json/default-4b4f3e8cc987c9e0/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-c02b7fcd7715c912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /data/junwang/.cache/huggingface/datasets/json/default-c02b7fcd7715c912/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53ae424377343698bb8242437fc11d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f50fbfd9cf1e414f9ba6be8079a7cfe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e0942bb0094d6ba152ca6b13ac4213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /data/junwang/.cache/huggingface/datasets/json/default-c02b7fcd7715c912/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-b90be606165a99b5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /data/junwang/.cache/huggingface/datasets/json/default-b90be606165a99b5/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da13175af96845dabd5231ec73e7ed1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fddfc3f16b849d1989848573b26d02b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b049d13d1749baa6dd139683aaacca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /data/junwang/.cache/huggingface/datasets/json/default-b90be606165a99b5/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-4b8d03d4fb3c98b0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /data/junwang/.cache/huggingface/datasets/json/default-4b8d03d4fb3c98b0/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0196e13a6ed24cb885a57fee0e28f2b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bfda397ee78457890105674cdbcf579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9641a523c4b74ae6b10e999dfb9ea48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /data/junwang/.cache/huggingface/datasets/json/default-4b8d03d4fb3c98b0/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:hf dataset: DatasetDict({\n",
      "    predict: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Tensor shapes:  {'input_ids': torch.Size([2, 50]), 'attention_mask': torch.Size([2, 50]), 'output_input_ids': torch.Size([2, 50]), 'output_attention_mask': torch.Size([2, 50]), 'input_multimodal_embedding_0': torch.Size([2, 100])} \n",
      "\n",
      "> Input toks:  ['Embed product with image: [title start] product_0 [title end] [image start]<extra_id_99> [image end]</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', 'Embed product with image: [title start] product_1 [title end] [image start]<extra_id_99> [image end]</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'] \n",
      "\n",
      "> output toks:  ['Embed taxonomy: baby > food</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', 'Embed taxonomy: baby > food</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for multimodal emb (title+image <> taxonomy)\n",
    "data = JSONListData(**{\n",
    "    \"llm_type\": \"emb\",\n",
    "    \"data_source_yaml_path\": \"/workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml\",\n",
    "    \"input_dict\": {\n",
    "        \"template\": (\"[title start] {title} [title end] \"\n",
    "            \"[image start] {image_embedding} [image end]\"),\n",
    "        \"task_prefix\": \"Embed product with image: \",\n",
    "        \"is_multimodal_embedding\": [\"image_embedding\"]\n",
    "    },\n",
    "    \"output_dict\": {\n",
    "        \"template\": \"{category}\",\n",
    "        \"task_prefix\": \"Embed taxonomy: \"\n",
    "    },\n",
    "    \"data_source_type\": \"local\",\n",
    "    \"transform_dict\": {\n",
    "        \"category\": \"taxonomy\"\n",
    "    },\n",
    "    \"overwrite_cache\": True\n",
    "})\n",
    "data.prepare_data()\n",
    "data.setup('predict')\n",
    "batch = data.ds['predict'][:2]\n",
    "print(\"> Tensor shapes: \", {i: batch[i].shape for i in batch}, '\\n')\n",
    "print(\"> Input toks: \", data.tokenizer.batch_decode(batch['input_ids']), '\\n')\n",
    "print(\"> output toks: \", data.tokenizer.batch_decode(batch['output_input_ids']), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Unused kwargs when getting t5-base: {}\n",
      "INFO:root:loading /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml from local\n",
      "INFO:root:Write predict.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Download local /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/tmp_multimodal_data.json from /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml now...\n",
      "1000it [00:00, 1649.55it/s]\n",
      "INFO:root:Successfully write predict.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Write test.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Download local /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/tmp_multimodal_data.json from /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml now...\n",
      "1000it [00:00, 1634.90it/s]\n",
      "INFO:root:Successfully write test.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Write train.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Download local /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/tmp_multimodal_data.json from /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml now...\n",
      "1000it [00:00, 1564.04it/s]\n",
      "INFO:root:Successfully write train.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Write val.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Download local /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/tmp_multimodal_data.json from /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml now...\n",
      "1000it [00:00, 1730.96it/s]\n",
      "INFO:root:Successfully write val.json.gz to /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c\n",
      "INFO:root:Convert data in /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c to Huggingface dataset\n",
      "WARNING:datasets.builder:Using custom data configuration default-08a55d75d3b6d448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /data/junwang/.cache/huggingface/datasets/json/default-08a55d75d3b6d448/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888914b796154b90aef8584ba879eb66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90be10c931094c9f8dbf64d28ee4bd22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456e63f91b2c461eb7cd38547abb15a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /data/junwang/.cache/huggingface/datasets/json/default-08a55d75d3b6d448/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-2f6b757130ddb708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /data/junwang/.cache/huggingface/datasets/json/default-2f6b757130ddb708/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7713034e720433e8445fff99bf9f4e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a9edd86bea45928bfd2dbac1ed294c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15fe424dbb5c44f6aa70d8fe7c01160e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /data/junwang/.cache/huggingface/datasets/json/default-2f6b757130ddb708/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-c2dbfdb22f848bc6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /data/junwang/.cache/huggingface/datasets/json/default-c2dbfdb22f848bc6/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a04da796c874b8da385c3430a50bbb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a26dd086f7487da7bd3fa68aa09452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db07abfa29e0434da0ad14a2a1d6c726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /data/junwang/.cache/huggingface/datasets/json/default-c2dbfdb22f848bc6/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-01f4089e610e5a6f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /data/junwang/.cache/huggingface/datasets/json/default-01f4089e610e5a6f/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945f9373f6354a5582a7b3ddc3fa4bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f193f6925f4c3aa468a908bccbf7f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851b3bb3e9e74af1ba405dd38e1459fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /data/junwang/.cache/huggingface/datasets/json/default-01f4089e610e5a6f/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:hf dataset: DatasetDict({\n",
      "    predict: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Tensor shapes:  {'input_ids': torch.Size([2, 50]), 'attention_mask': torch.Size([2, 50]), 'output_input_ids': torch.Size([2, 50]), 'output_attention_mask': torch.Size([2, 50])} \n",
      "\n",
      "> Input toks:  ['Embed product: product_0</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', 'Embed product: product_1</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'] \n",
      "\n",
      "> output toks:  ['Embed taxonomy: baby > food</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', 'Embed taxonomy: baby > food</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for singlemodal emb (title <> taxonomy)\n",
    "data = JSONListData(**{\n",
    "    \"llm_type\": \"emb\",\n",
    "    \"data_source_yaml_path\": \"/workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml\",\n",
    "    \"input_dict\": {\n",
    "        \"template\": \"{title}\",\n",
    "        \"task_prefix\": \"Embed product: \"\n",
    "    },\n",
    "    \"output_dict\": {\n",
    "        \"template\": \"{category}\",\n",
    "        \"task_prefix\": \"Embed taxonomy: \"\n",
    "    },\n",
    "    \"data_source_type\": \"local\",\n",
    "    \"transform_dict\": {\n",
    "        \"category\": \"taxonomy\"\n",
    "    },\n",
    "    \"overwrite_cache\": True\n",
    "})\n",
    "data.prepare_data()\n",
    "data.setup('predict')\n",
    "batch = data.ds['predict'][:2]\n",
    "print(\"> Tensor shapes: \", {i: batch[i].shape for i in batch}, '\\n')\n",
    "print(\"> Input toks: \", data.tokenizer.batch_decode(batch['input_ids']), '\\n')\n",
    "print(\"> output toks: \", data.tokenizer.batch_decode(batch['output_input_ids']), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Unused kwargs when getting t5-base: {}\n",
      "INFO:root:Use cache stored in /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c for /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml\n",
      "INFO:root:Convert data in /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c to Huggingface dataset\n",
      "WARNING:datasets.builder:Using custom data configuration default-08a55d75d3b6d448\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-08a55d75d3b6d448/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "WARNING:datasets.builder:Using custom data configuration default-2f6b757130ddb708\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-2f6b757130ddb708/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "WARNING:datasets.builder:Using custom data configuration default-c2dbfdb22f848bc6\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-c2dbfdb22f848bc6/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "WARNING:datasets.builder:Using custom data configuration default-01f4089e610e5a6f\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-01f4089e610e5a6f/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "INFO:root:hf dataset: DatasetDict({\n",
      "    predict: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Tensor shapes:  {'input_ids': torch.Size([2, 50]), 'attention_mask': torch.Size([2, 50]), 'labels': torch.Size([2, 50])} \n",
      "\n",
      "> Input toks:  ['Denoise product: prod<extra_id_0> c<extra_id_1> _0</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', 'Denoise product:<extra_id_0> r<extra_id_1> duct_1</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'] \n",
      "\n",
      "> Output toks:  ['<extra_id_0> u<extra_id_1> t<extra_id_2></s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', '<extra_id_0> p<extra_id_1> o<extra_id_2></s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for singlemodal dlm (title denoising)\n",
    "data = JSONListData(**{\n",
    "    \"llm_type\": \"dlm\",\n",
    "    \"data_source_yaml_path\": \"/workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml\",\n",
    "    \"input_dict\": {\n",
    "        \"template\": \"{title}\",\n",
    "        \"task_prefix\": \"Denoise product: \"\n",
    "    },\n",
    "    \"output_dict\": {\n",
    "        \"template\": \"{title}\"\n",
    "    },\n",
    "    \"data_source_type\": \"local\"\n",
    "})\n",
    "data.prepare_data()\n",
    "data.setup('predict')\n",
    "batch = data.ds['predict'][:2]\n",
    "print(\"> Tensor shapes: \", {i: batch[i].shape for i in batch}, '\\n')\n",
    "print(\"> Input toks: \", data.tokenizer.batch_decode(batch['input_ids']), '\\n')\n",
    "tmp = batch['labels']\n",
    "tmp[tmp==-100] = 0\n",
    "print(\"> Output toks: \", data.tokenizer.batch_decode(tmp), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Unused kwargs when getting t5-base: {}\n",
      "INFO:root:Use cache stored in /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c for /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml\n",
      "INFO:root:Convert data in /data/junwang/.cache/general/64cf6745c4c72099f0692e7e1ee6a06c to Huggingface dataset\n",
      "WARNING:datasets.builder:Using custom data configuration default-08a55d75d3b6d448\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-08a55d75d3b6d448/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "WARNING:datasets.builder:Using custom data configuration default-2f6b757130ddb708\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-2f6b757130ddb708/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "WARNING:datasets.builder:Using custom data configuration default-c2dbfdb22f848bc6\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-c2dbfdb22f848bc6/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "WARNING:datasets.builder:Using custom data configuration default-01f4089e610e5a6f\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-01f4089e610e5a6f/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "INFO:root:hf dataset: DatasetDict({\n",
      "    predict: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Tensor shapes:  {'input_ids': torch.Size([2, 50]), 'attention_mask': torch.Size([2, 50]), 'labels': torch.Size([2, 50])} \n",
      "\n",
      "> Input toks:  ['Top-down categorize product: product_0</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', 'Top-down categorize product: product_1</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'] \n",
      "\n",
      "> Output toks:  ['baby > food</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', 'baby > food</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for singlemodal clm (taxonomy generation)\n",
    "data = JSONListData(**{\n",
    "    \"llm_type\": \"clm\",\n",
    "    \"data_source_yaml_path\": \"/workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml\",\n",
    "    \"input_dict\": {\n",
    "            \"template\": \"{title}\",\n",
    "            \"task_prefix\": \"Top-down categorize product: \"\n",
    "        },\n",
    "    \"output_dict\": {\n",
    "        \"template\": \"{category}\"\n",
    "    },\n",
    "    \"data_source_type\": \"local\",\n",
    "    \"transform_dict\": {\n",
    "        \"category\": \"taxonomy\"\n",
    "    }\n",
    "})\n",
    "data.prepare_data()\n",
    "data.setup('predict')\n",
    "batch = data.ds['predict'][:2]\n",
    "print(\"> Tensor shapes: \", {i: batch[i].shape for i in batch}, '\\n')\n",
    "print(\"> Input toks: \", data.tokenizer.batch_decode(batch['input_ids']), '\\n')\n",
    "tmp = batch['labels']\n",
    "tmp[tmp==-100] = 0\n",
    "print(\"> Output toks: \", data.tokenizer.batch_decode(tmp), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Unused kwargs when getting t5-base: {}\n",
      "INFO:root:Use cache stored in /data/junwang/.cache/general/6c567415c26cb7620fb8c8373a4ef972 for /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml\n",
      "INFO:root:Convert data in /data/junwang/.cache/general/6c567415c26cb7620fb8c8373a4ef972 to Huggingface dataset\n",
      "WARNING:datasets.builder:Using custom data configuration default-e503b12711d6c137\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-e503b12711d6c137/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "WARNING:datasets.builder:Using custom data configuration default-5d9263d1fbf06ff3\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-5d9263d1fbf06ff3/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "WARNING:datasets.builder:Using custom data configuration default-9fc6d205aa758952\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-9fc6d205aa758952/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "WARNING:datasets.builder:Using custom data configuration default-3d8d92b353676b93\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-3d8d92b353676b93/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "INFO:root:hf dataset: DatasetDict({\n",
      "    predict: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Tensor shapes:  {'input_ids': torch.Size([2, 50]), 'attention_mask': torch.Size([2, 50]), 'labels': torch.Size([2, 6037])} \n",
      "\n",
      "> Input toks:  ['Classify product: product_0</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', 'Classify product: product_1</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'] \n",
      "\n",
      "> Output labs:  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for singlemodal seqclf (taxonomy classification)\n",
    "data = JSONListData(**{\n",
    "    \"data_source_yaml_path\": \"/workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal.yaml\",\n",
    "    \"label_map_file\": \"/workspaces/multitask-llm-rnd/modelling/datasets/taxonomy/wish_v1.2.1_newtax_allpaths.txt\",\n",
    "    \"label_type\": \"taxonomy\", \n",
    "    \"llm_type\": \"seqclf\",\n",
    "    \"input_dict\": {\n",
    "        \"template\": \"{title}\",\n",
    "        \"task_prefix\": \"Classify product: \"\n",
    "    },\n",
    "    \"output_dict\": {\n",
    "        \"template\": \"{category}\"\n",
    "    },\n",
    "    \"data_source_type\": \"local\"\n",
    "})\n",
    "data.prepare_data()\n",
    "data.setup('predict')\n",
    "batch = data.ds['predict'][:2]\n",
    "print(\"> Tensor shapes: \", {i: batch[i].shape for i in batch}, '\\n')\n",
    "print(\"> Input toks: \", data.tokenizer.batch_decode(batch['input_ids']), '\\n')\n",
    "tmp = batch['labels']\n",
    "print(\"> Output labs: \", tmp, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multitask multimodal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Unused kwargs when getting t5-base: {}\n",
      "/opt/conda/envs/py38/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "INFO:root:Unused kwargs when getting t5-base: {}\n",
      "INFO:root:Unused kwargs when getting t5-base: {}\n",
      "INFO:root:Unused kwargs when getting t5-base: {}\n",
      "INFO:root:Unused kwargs when getting t5-base: {}\n",
      "INFO:root:Unused kwargs when getting t5-base: {}\n",
      "INFO:root:Use cache stored in /data/junwang/.cache/general/253c12288fbeccfa55bc6ee0429994af for /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal_full.yaml\n",
      "INFO:root:Use cache stored in /data/junwang/.cache/general/253c12288fbeccfa55bc6ee0429994af for /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal_full.yaml\n",
      "INFO:root:Use cache stored in /data/junwang/.cache/general/f8c49ca98d7353e0cd402f4c7c40c56e for /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal_full.yaml\n",
      "INFO:root:Use cache stored in /data/junwang/.cache/general/60c33190a0431a1ee86b7c97c4ac06f3 for /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal_full.yaml\n",
      "INFO:root:Use cache stored in /data/junwang/.cache/general/253c12288fbeccfa55bc6ee0429994af for /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal_full.yaml\n",
      "INFO:root:Use cache stored in /data/junwang/.cache/general/253c12288fbeccfa55bc6ee0429994af for /workspaces/multitask-llm-rnd/modelling/datasets/demo_local/demo_local_multimodal_full.yaml\n",
      "INFO:root:Convert data in /data/junwang/.cache/general/253c12288fbeccfa55bc6ee0429994af to Huggingface dataset\n",
      "WARNING:datasets.builder:Using custom data configuration default-02589b1078e2fca0\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-02589b1078e2fca0/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "WARNING:datasets.builder:Using custom data configuration default-957241c94ea63d81\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-957241c94ea63d81/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "WARNING:datasets.builder:Using custom data configuration default-45bb16a82462d0b3\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-45bb16a82462d0b3/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "WARNING:datasets.builder:Using custom data configuration default-e96bf5a5271e6f43\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-e96bf5a5271e6f43/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "INFO:root:hf dataset: DatasetDict({\n",
      "    predict: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n",
      "INFO:root:Convert data in /data/junwang/.cache/general/253c12288fbeccfa55bc6ee0429994af to Huggingface dataset\n",
      "WARNING:datasets.builder:Using custom data configuration default-02589b1078e2fca0\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-02589b1078e2fca0/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "WARNING:datasets.builder:Using custom data configuration default-957241c94ea63d81\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-957241c94ea63d81/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "WARNING:datasets.builder:Using custom data configuration default-45bb16a82462d0b3\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-45bb16a82462d0b3/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "WARNING:datasets.builder:Using custom data configuration default-e96bf5a5271e6f43\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-e96bf5a5271e6f43/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "INFO:root:hf dataset: DatasetDict({\n",
      "    predict: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n",
      "INFO:root:Convert data in /data/junwang/.cache/general/f8c49ca98d7353e0cd402f4c7c40c56e to Huggingface dataset\n",
      "WARNING:datasets.builder:Using custom data configuration default-c716f6c484afc151\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-c716f6c484afc151/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "WARNING:datasets.builder:Using custom data configuration default-b9110c9f9e480098\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-b9110c9f9e480098/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "WARNING:datasets.builder:Using custom data configuration default-1fcadcde891b4180\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-1fcadcde891b4180/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "WARNING:datasets.builder:Using custom data configuration default-986d128aab544ac6\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-986d128aab544ac6/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "INFO:root:hf dataset: DatasetDict({\n",
      "    predict: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n",
      "INFO:root:Convert data in /data/junwang/.cache/general/60c33190a0431a1ee86b7c97c4ac06f3 to Huggingface dataset\n",
      "WARNING:datasets.builder:Using custom data configuration default-39ede8af13e62b03\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-39ede8af13e62b03/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "WARNING:datasets.builder:Using custom data configuration default-400f0ce113e5e7b1\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-400f0ce113e5e7b1/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "WARNING:datasets.builder:Using custom data configuration default-4447030255380653\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-4447030255380653/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "WARNING:datasets.builder:Using custom data configuration default-207a1cef53964951\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-207a1cef53964951/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "INFO:root:hf dataset: DatasetDict({\n",
      "    predict: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n",
      "INFO:root:Convert data in /data/junwang/.cache/general/253c12288fbeccfa55bc6ee0429994af to Huggingface dataset\n",
      "WARNING:datasets.builder:Using custom data configuration default-02589b1078e2fca0\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-02589b1078e2fca0/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "WARNING:datasets.builder:Using custom data configuration default-957241c94ea63d81\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-957241c94ea63d81/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "WARNING:datasets.builder:Using custom data configuration default-45bb16a82462d0b3\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-45bb16a82462d0b3/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "WARNING:datasets.builder:Using custom data configuration default-e96bf5a5271e6f43\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-e96bf5a5271e6f43/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "INFO:root:hf dataset: DatasetDict({\n",
      "    predict: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n",
      "INFO:root:Convert data in /data/junwang/.cache/general/253c12288fbeccfa55bc6ee0429994af to Huggingface dataset\n",
      "WARNING:datasets.builder:Using custom data configuration default-02589b1078e2fca0\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-02589b1078e2fca0/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "WARNING:datasets.builder:Using custom data configuration default-957241c94ea63d81\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-957241c94ea63d81/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "WARNING:datasets.builder:Using custom data configuration default-45bb16a82462d0b3\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-45bb16a82462d0b3/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "WARNING:datasets.builder:Using custom data configuration default-e96bf5a5271e6f43\n",
      "WARNING:datasets.builder:Found cached dataset json (/data/junwang/.cache/huggingface/datasets/json/default-e96bf5a5271e6f43/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "INFO:root:hf dataset: DatasetDict({\n",
      "    predict: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['json_content'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clm_multimodal_clip2wishtitle': dict_keys(['input_ids', 'attention_mask', 'labels', 'input_multimodal_embedding_0']),\n",
      " 'dlm_multimodal_wishtitlewclip': dict_keys(['input_ids', 'attention_mask', 'labels', 'input_multimodal_embedding_0']),\n",
      " 'emb_singlemodal_amaquery2amatitle_manual': dict_keys(['input_ids', 'attention_mask', 'output_input_ids', 'output_attention_mask']),\n",
      " 'emb_singlemodal_wishquery2googletitle': dict_keys(['input_ids', 'attention_mask', 'output_input_ids', 'output_attention_mask']),\n",
      " 'seqclf_multimodal_wishtitlewclip2pseudov121tax': dict_keys(['input_ids', 'attention_mask', 'labels', 'input_multimodal_embedding_0']),\n",
      " 'seqclf_singlemodal_alititle2v121tax': dict_keys(['input_ids', 'attention_mask', 'labels'])}\n"
     ]
    }
   ],
   "source": [
    "data = LLM_MultitaskMultiModalData(num_workers=2)\n",
    "data.prepare_data()\n",
    "data.setup('train')\n",
    "dl = data.train_dataloader()\n",
    "for batch in dl:\n",
    "    pprint({i: batch[i].keys() for i in batch})\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_utils import get_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Unused kwargs when getting t5-base: {}\n",
      "/opt/conda/envs/py38/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "_, tokenizer = get_transformer('t5-base', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >  clm_multimodal_clip2wishtitle input_ids\n",
      "['Generate title for product with image: [image start]<extra_id_99> [image end]</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']\n",
      " >  clm_multimodal_clip2wishtitle attention_mask\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])\n",
      " >  clm_multimodal_clip2wishtitle labels\n",
      "['product_870 a really nice product</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']\n",
      " >  clm_multimodal_clip2wishtitle input_multimodal_embedding_0\n",
      "tensor([[7.4735e-01, 8.4679e-01, 2.1023e-01, 7.2435e-01, 8.5117e-01, 9.9807e-01,\n",
      "         9.7209e-02, 8.6281e-01, 1.8842e-01, 1.0188e-02, 9.8686e-01, 9.7464e-01,\n",
      "         8.0496e-01, 6.3882e-01, 8.6184e-01, 4.6335e-01, 4.7211e-01, 5.4563e-01,\n",
      "         3.0524e-01, 1.6509e-01, 4.5983e-01, 1.1229e-01, 1.6284e-01, 2.9566e-01,\n",
      "         1.8973e-01, 4.3538e-01, 5.6036e-01, 9.8277e-01, 8.4946e-01, 7.9163e-01,\n",
      "         9.2332e-01, 6.4349e-02, 7.7297e-01, 6.4594e-01, 2.1870e-01, 3.2953e-01,\n",
      "         1.6157e-01, 7.7501e-01, 8.1580e-03, 5.1025e-01, 2.8235e-01, 4.5387e-01,\n",
      "         2.2477e-01, 3.6872e-01, 4.4521e-02, 8.1033e-01, 4.1600e-01, 6.2127e-01,\n",
      "         3.6222e-01, 3.1994e-01, 6.9591e-01, 5.2647e-01, 5.1221e-03, 9.7928e-01,\n",
      "         7.0361e-01, 4.2312e-01, 3.0903e-01, 9.6245e-01, 6.5997e-01, 6.3155e-01,\n",
      "         8.3525e-01, 7.2543e-01, 8.2747e-01, 2.3152e-01, 7.6236e-01, 7.2186e-01,\n",
      "         6.0438e-01, 6.3932e-01, 3.7288e-01, 4.5277e-04, 9.4395e-01, 9.7968e-01,\n",
      "         4.2319e-01, 6.1047e-01, 4.4788e-01, 3.0754e-01, 8.6388e-01, 6.6462e-01,\n",
      "         2.9628e-01, 1.9165e-01, 2.6752e-01, 4.5325e-01, 6.3704e-02, 4.1249e-01,\n",
      "         1.5851e-01, 6.8186e-02, 9.7821e-01, 6.2131e-01, 4.8778e-01, 8.5849e-01,\n",
      "         3.0348e-01, 9.5243e-02, 9.2460e-01, 4.5882e-01, 6.4053e-01, 4.4222e-01,\n",
      "         8.0075e-02, 2.2761e-01, 6.0502e-01, 8.4989e-01]])\n",
      " >  dlm_multimodal_wishtitlewclip input_ids\n",
      "['Denoise product with image: [title start]<extra_id_0> a really nice product [title end] [image start]<extra_id_99> [image end]</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']\n",
      " >  dlm_multimodal_wishtitlewclip attention_mask\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])\n",
      " >  dlm_multimodal_wishtitlewclip labels\n",
      "['<extra_id_0> product_909<extra_id_1></s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']\n",
      " >  dlm_multimodal_wishtitlewclip input_multimodal_embedding_0\n",
      "tensor([[0.6407, 0.3960, 0.3866, 0.0936, 0.3673, 0.6241, 0.8800, 0.9626, 0.7192,\n",
      "         0.9918, 0.4819, 0.2208, 0.7423, 0.6211, 0.5010, 0.3025, 0.5944, 0.4797,\n",
      "         0.3696, 0.0748, 0.3293, 0.5513, 0.8588, 0.1565, 0.6198, 0.9924, 0.5095,\n",
      "         0.7282, 0.6181, 0.9854, 0.1361, 0.3597, 0.3882, 0.3786, 0.1214, 0.6962,\n",
      "         0.8805, 0.6092, 0.6175, 0.1490, 0.5349, 0.2133, 0.1913, 0.5847, 0.8222,\n",
      "         0.5721, 0.3835, 0.7396, 0.9194, 0.9320, 0.4432, 0.1497, 0.6079, 0.7711,\n",
      "         0.5519, 0.5013, 0.2450, 0.0929, 0.9158, 0.8176, 0.2868, 0.6554, 0.0051,\n",
      "         0.1901, 0.1158, 0.8064, 0.0761, 0.9060, 0.9875, 0.3068, 0.8112, 0.6036,\n",
      "         0.4774, 0.6670, 0.5892, 0.8295, 0.6175, 0.8935, 0.2817, 0.9358, 0.1196,\n",
      "         0.2536, 0.5139, 0.3358, 0.6273, 0.1295, 0.5462, 0.3439, 0.4263, 0.4719,\n",
      "         0.2486, 0.7585, 0.7796, 0.9240, 0.4602, 0.6122, 0.7846, 0.0763, 0.7172,\n",
      "         0.2397]])\n",
      " >  seqclf_multimodal_wishtitlewclip2pseudov121tax input_ids\n",
      "['Classify product with image: [title start] product_266 a really nice product [title end] [image start]<extra_id_99> [image end]</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']\n",
      " >  seqclf_multimodal_wishtitlewclip2pseudov121tax attention_mask\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])\n",
      " >  seqclf_multimodal_wishtitlewclip2pseudov121tax labels\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]])\n",
      " >  seqclf_multimodal_wishtitlewclip2pseudov121tax input_multimodal_embedding_0\n",
      "tensor([[0.1744, 0.7117, 0.1244, 0.3190, 0.7978, 0.0211, 0.6683, 0.4386, 0.2168,\n",
      "         0.7559, 0.5286, 0.5584, 0.2889, 0.9180, 0.5491, 0.0195, 0.0280, 0.8142,\n",
      "         0.5369, 0.2515, 0.8924, 0.9107, 0.6930, 0.2539, 0.6152, 0.8244, 0.0841,\n",
      "         0.4361, 0.2923, 0.4189, 0.6479, 0.2202, 0.9463, 0.0654, 0.3501, 0.2666,\n",
      "         0.7254, 0.6037, 0.0928, 0.4663, 0.3358, 0.5116, 0.6500, 0.9180, 0.8232,\n",
      "         0.7078, 0.2216, 0.6473, 0.4104, 0.0429, 0.0187, 0.3356, 0.5728, 0.3782,\n",
      "         0.4132, 0.7667, 0.4947, 0.1760, 0.1296, 0.3811, 0.5603, 0.3838, 0.9319,\n",
      "         0.3439, 0.4942, 0.7763, 0.1161, 0.4516, 0.4866, 0.6500, 0.4242, 0.2355,\n",
      "         0.4970, 0.3918, 0.5430, 0.9529, 0.1347, 0.7360, 0.6799, 0.7513, 0.4681,\n",
      "         0.8496, 0.3377, 0.5376, 0.4687, 0.8694, 0.1825, 0.6374, 0.6681, 0.7131,\n",
      "         0.4790, 0.6504, 0.4877, 0.9827, 0.2568, 0.4091, 0.7983, 0.6455, 0.0579,\n",
      "         0.5140]])\n",
      " >  seqclf_singlemodal_alititle2v121tax input_ids\n",
      "['Classify product: product_575 a really nice product</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']\n",
      " >  seqclf_singlemodal_alititle2v121tax attention_mask\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])\n",
      " >  seqclf_singlemodal_alititle2v121tax labels\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]])\n",
      " >  emb_singlemodal_wishquery2googletitle input_ids\n",
      "['Embed product: product_946 a really nice product</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']\n",
      " >  emb_singlemodal_wishquery2googletitle attention_mask\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])\n",
      " >  emb_singlemodal_wishquery2googletitle output_input_ids\n",
      "['Embed query: query_946 a really nice query</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']\n",
      " >  emb_singlemodal_wishquery2googletitle output_attention_mask\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])\n",
      " >  emb_singlemodal_amaquery2amatitle_manual input_ids\n",
      "['Embed product: product_232 a really nice product</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']\n",
      " >  emb_singlemodal_amaquery2amatitle_manual attention_mask\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])\n",
      " >  emb_singlemodal_amaquery2amatitle_manual output_input_ids\n",
      "['Embed query: query_232 a really nice query</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']\n",
      " >  emb_singlemodal_amaquery2amatitle_manual output_attention_mask\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])\n"
     ]
    }
   ],
   "source": [
    "for task in batch:\n",
    "    for k in batch[task]:\n",
    "        if 'input_ids' in k or (k == 'labels' and (task.startswith('clm') or task.startswith('dlm'))):\n",
    "            print(\" > \", task, k)\n",
    "            batch[task][k][batch[task][k] == -100] = 0\n",
    "            print(tokenizer.batch_decode(batch[task][k][:1]))\n",
    "        else:\n",
    "            print(\" > \", task, k)\n",
    "            print(batch[task][k][:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ea19d11efa7602c1f12500925a974ed4f31fcf847bd6f694bd5180da2602ded"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
