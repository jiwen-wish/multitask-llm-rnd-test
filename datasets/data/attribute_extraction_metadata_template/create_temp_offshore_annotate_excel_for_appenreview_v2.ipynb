{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import hashlib\n",
    "from tqdm import tqdm\n",
    "import xlsxwriter\n",
    "from xlsxwriter.utility import xl_rowcol_to_cell\n",
    "import dvc.api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from copy import deepcopy \n",
    "\n",
    "def sortOD(od):\n",
    "    res = OrderedDict()\n",
    "    for k, v in sorted(od.items()):\n",
    "        if isinstance(v, dict):\n",
    "            res[k] = sortOD(v)\n",
    "        else:\n",
    "            res[k] = deepcopy(v)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2s = []\n",
    "with open('2023_q1_top_25_l2s.txt', 'r') as f:\n",
    "    for l in f:\n",
    "        if len(l.replace('\\n', '').strip()) > 0:\n",
    "            l2s.append(l.replace('\\n', '').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv(\"Initial Attribute Definition for First Release - UPDATED SHEET .csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_25l2s = df_meta[df_meta.category.apply(lambda x: any([x.startswith(i) for i in l2s]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df_meta_25l2s.category.apply(lambda x: ' > '.join(x.split(' > ')[:2]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11027/1116168472.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_meta_25l2s['L2'] = df_meta_25l2s.category.apply(lambda x: ' > '.join(x.split(' > ')[:2]))\n"
     ]
    }
   ],
   "source": [
    "df_meta_25l2s['L2'] = df_meta_25l2s.category.apply(lambda x: ' > '.join(x.split(' > ')[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_25l2s_nofreetext = df_meta_25l2s[df_meta_25l2s['entry mode'] != 'free_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dict = {}\n",
    "for i in set(df_meta.category):\n",
    "    meta_dict[i] = df_meta[(df_meta.category == i) & (df_meta['entry mode'] != 'free_text')].sort_values(\n",
    "        \"attribute_field\"\n",
    "    ).to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query = pd.read_csv(dvc.api.get_url(\n",
    "    'modelling/notebooks/query_attr_extract_appen_label/appen_query_attribution_batch1.csv',\n",
    "    repo='git@github.com:ContextLogic/multitask-llm-rnd.git'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product = pd.read_csv(dvc.api.get_url(\n",
    "    'datasets/data/wish_attr_extract_label/appen/input_batch_processed/appen_product_attribution_batch1.csv',\n",
    "    repo='git@github.com:ContextLogic/multitask-llm-rnd.git'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_appen = pd.read_csv(dvc.api.get_url(\n",
    "    'datasets/data/query_attr_extract_label/appen/output_batch_correct_v2/feedback/query_attribution_02.03.23_valid_units_02.21.23.csv',\n",
    "    repo='git@github.com:ContextLogic/multitask-llm-rnd.git'\n",
    "))\n",
    "\n",
    "df_product_appen = pd.read_csv(dvc.api.get_url(\n",
    "    'datasets/data/wish_attr_extract_label/appen/output_batch_correct_v2/feedback/product_attribution_02.03.23_valid_units_02.21.23.csv',\n",
    "    repo='git@github.com:ContextLogic/multitask-llm-rnd.git'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_label_orderings = set(df_product_appen.sort_values('Label_Ordering').tail(100)['Label_Ordering'])\n",
    "query_label_orderings = set(df_query_appen.sort_values('Label_Ordering').tail(100)['Label_Ordering'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query = df_query[df_query.label_ordering.apply(lambda x: int(x) in query_label_orderings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmp(x):\n",
    "    try:\n",
    "        return int(x) in product_label_orderings\n",
    "    except:\n",
    "        return False\n",
    "df_product = df_product[df_product.label_ordering.apply(tmp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_query), len(df_product)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1601.86it/s]\n"
     ]
    }
   ],
   "source": [
    "recs = []\n",
    "for i in tqdm(df_product.to_dict('records')):\n",
    "    if i['category_path'] in meta_dict:\n",
    "        for j in meta_dict[i['category_path']]:\n",
    "            rec = sortOD({\n",
    "                \"category_path\": i['category_path'],\n",
    "                \"product_id\": i['product_id'],\n",
    "                \"title\": i['title'],\n",
    "                \"product_description\": i['product_description'],\n",
    "                \"main_image_url\": i['main_image_url'],\n",
    "                \"attribute_field\": j['attribute_field'],\n",
    "                \"attribute_value\": j['category_attributevalue'],\n",
    "                \"entry_mode\": j['entry mode'],\n",
    "                \"max_multi_select\": str(j['max_multi_select']),\n",
    "                \"attribute_description\": j['description']\n",
    "            })\n",
    "            task_json = json.dumps(rec).encode('utf-8')\n",
    "            task_hash = hashlib.md5(task_json).hexdigest()\n",
    "            task_id = f\"product_attribution_{task_hash}\"\n",
    "            rec['task_id'] = task_id\n",
    "            recs.append(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.DataFrame(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(tmp_df) == len(set(tmp_df.task_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(tmp_df['product_id'])) / len(df_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.57"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp_df) / len(set(tmp_df['product_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1057/1057 [00:00<00:00, 9990.20it/s] \n"
     ]
    }
   ],
   "source": [
    "attr_val_set_to_cell_range = {}\n",
    "\n",
    "workbook = xlsxwriter.Workbook('offshore_review_appen/product_attribute_extraction_offshore_batch2.xlsx')\n",
    "worksheet = workbook.add_worksheet('attribute_val')\n",
    "worksheet2 = workbook.add_worksheet('attribute_definition')\n",
    "\n",
    "r = 0\n",
    "for i in set(tmp_df['attribute_value']):\n",
    "    c = 0\n",
    "    start_cell = xl_rowcol_to_cell(r, c, row_abs=True, col_abs=True)\n",
    "    end_cell = xl_rowcol_to_cell(r, c, row_abs=True, col_abs=True)\n",
    "    for j in eval(i):\n",
    "        worksheet2.write(r, c, j)\n",
    "        end_cell = xl_rowcol_to_cell(r, c, row_abs=True, col_abs=True)\n",
    "        c += 1\n",
    "    attr_val_set_to_cell_range[i] = (start_cell, end_cell)\n",
    "    r += 1\n",
    "\n",
    "\n",
    "cols = ['task_id', 'category_path', 'title', 'product_description', 'main_image_url', \n",
    "    'max_multi_select', 'entry_mode', 'attribute_field', 'attribute_value']\n",
    "\n",
    "r = 0\n",
    "for c in range(len(cols)):\n",
    "    worksheet.write(r, c, cols[c])\n",
    "\n",
    "worksheet.write(r, len(cols), 'custom_value')\n",
    "worksheet.write(r, len(cols) + 1, 'comments')\n",
    "\n",
    "r += 1\n",
    "for i in tqdm(tmp_df.to_dict('records')):\n",
    "    for c in range(len(cols)):\n",
    "        if cols[c] != 'attribute_value':\n",
    "            worksheet.write(r, c, str(i[cols[c]]))\n",
    "        else:\n",
    "            start_cell, end_cell = attr_val_set_to_cell_range[i[cols[c]]]\n",
    "            worksheet.data_validation(r, c, r, c, {\n",
    "                'validate': 'list',\n",
    "                'source': f'=attribute_definition!{start_cell}:{end_cell}',\n",
    "                'input_message': i['attribute_description']\n",
    "            })\n",
    "    r += 1\n",
    "\n",
    "workbook.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 288.71it/s]\n"
     ]
    }
   ],
   "source": [
    "recs = []\n",
    "for i in tqdm(df_query.to_dict('records')):\n",
    "    path_i_tup = tuple(i['top_query_classification_taxonomy'].split(' > '))\n",
    "    for path in meta_dict:\n",
    "        if tuple(path.split(' > '))[:len(path_i_tup)] == path_i_tup:\n",
    "            for j in meta_dict[path]:\n",
    "                rec = sortOD({\n",
    "                    \"category_path\": i['top_query_classification_taxonomy'],\n",
    "                    \"query\": i['query'],\n",
    "                    \"attribute_field\": j['attribute_field'],\n",
    "                    \"attribute_value\": j['category_attributevalue'],\n",
    "                    \"entry_mode\": j['entry mode'],\n",
    "                    \"max_multi_select\": str(j['max_multi_select']),\n",
    "                    \"attribute_description\": j['description']\n",
    "                })\n",
    "                task_json = json.dumps(rec).encode('utf-8')\n",
    "                task_hash = hashlib.md5(task_json).hexdigest()\n",
    "                task_id = f\"query_attribution_{task_hash}\"\n",
    "                rec['task_id'] = task_id\n",
    "                recs.append(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.DataFrame(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = tmp_df.drop_duplicates('task_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(tmp_df['query'])) / len(df_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.43"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp_df) / len(set(tmp_df['query']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1143/1143 [00:00<00:00, 14975.87it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "attr_val_set_to_cell_range = {}\n",
    "\n",
    "workbook = xlsxwriter.Workbook('offshore_review_appen/query_attribute_extraction_offshore_batch2.xlsx')\n",
    "worksheet = workbook.add_worksheet('attribute_val')\n",
    "worksheet2 = workbook.add_worksheet('attribute_definition')\n",
    "\n",
    "r = 0\n",
    "for i in set(tmp_df['attribute_value']):\n",
    "    c = 0\n",
    "    start_cell = xl_rowcol_to_cell(r, c, row_abs=True, col_abs=True)\n",
    "    end_cell = xl_rowcol_to_cell(r, c, row_abs=True, col_abs=True)\n",
    "    for j in eval(i):\n",
    "        worksheet2.write(r, c, j)\n",
    "        end_cell = xl_rowcol_to_cell(r, c, row_abs=True, col_abs=True)\n",
    "        c += 1\n",
    "    attr_val_set_to_cell_range[i] = (start_cell, end_cell)\n",
    "    r += 1\n",
    "\n",
    "cols = ['task_id', 'category_path', 'query', \n",
    "    'max_multi_select', 'entry_mode', 'attribute_field', 'attribute_value']\n",
    "\n",
    "r = 0\n",
    "for c in range(len(cols)):\n",
    "    worksheet.write(r, c, cols[c])\n",
    "\n",
    "worksheet.write(r, len(cols), 'custom_value')\n",
    "worksheet.write(r, len(cols) + 1, 'comments')\n",
    "\n",
    "r += 1\n",
    "for i in tqdm(tmp_df.to_dict('records')):\n",
    "    for c in range(len(cols)):\n",
    "        if cols[c] != 'attribute_value':\n",
    "            worksheet.write(r, c, i[cols[c]])\n",
    "        else:\n",
    "            start_cell, end_cell = attr_val_set_to_cell_range[i[cols[c]]]\n",
    "            worksheet.data_validation(r, c, r, c, {\n",
    "                'validate': 'list',\n",
    "                'source': f'=attribute_definition!{start_cell}:{end_cell}',\n",
    "                'input_message': i['attribute_description']\n",
    "            })\n",
    "    r += 1\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
