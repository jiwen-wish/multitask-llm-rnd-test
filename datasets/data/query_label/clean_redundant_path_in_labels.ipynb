{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "tmp = pd.read_json('../query/Inferred_Multiple_Wish_Query_Meta_Train.json', lines=True)\n",
    "tmp['split'] = 'infer_train'\n",
    "dfs.append(tmp)\n",
    "\n",
    "tmp = pd.read_json('../query/Inferred_Multiple_Wish_Query_Meta_Val.json', lines=True)\n",
    "tmp['split'] = 'infer_val'\n",
    "dfs.append(tmp)\n",
    "\n",
    "tmp = pd.read_json('../query/Inferred_Multiple_Wish_Query_Meta_Test.json', lines=True)\n",
    "tmp['split'] = 'infer_test'\n",
    "dfs.append(tmp)\n",
    "\n",
    "tmp = pd.read_json('processed2/Human_Labelled_Query_Classification_Train.json', lines=True)\n",
    "tmp['split'] = 'label_train'\n",
    "dfs.append(tmp)\n",
    "\n",
    "tmp = pd.read_json('processed2/Human_Labelled_Query_Classification_Val.json', lines=True)\n",
    "tmp['split'] = 'label_val'\n",
    "dfs.append(tmp)\n",
    "\n",
    "tmp = pd.read_json('processed2/Human_Labelled_Query_Classification_Test.json', lines=True)\n",
    "tmp['split'] = 'label_test'\n",
    "dfs.append(tmp)\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "del dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group = df.groupby('query').agg({'category': lambda x: [i for i in x], 'split': lambda x: [i for i in x]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2846418"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group = df_group.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_to_rm_from_infer = set(df_group[df_group.split.apply(lambda x: len(set(x)) > 1 and ('label_test' in x or 'label_val' in x))]['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2846418/2846418 [00:02<00:00, 997129.68it/s] \n"
     ]
    }
   ],
   "source": [
    "recs = []\n",
    "for i in tqdm(df_group.to_dict('records')):\n",
    "    cats = [] \n",
    "    splits = []\n",
    "    if i['query'] in queries_to_rm_from_infer:\n",
    "        for cat, split in zip(i['category'], i['split']):\n",
    "            if 'infer' not in split:\n",
    "                cats.append(cat)\n",
    "                splits.append(split)\n",
    "        i['category'] = cats \n",
    "        i['split'] = splits \n",
    "    recs.append(i)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group = pd.DataFrame(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prefix_strings(strings_in):\n",
    "    res = set(strings_in)\n",
    "    strings = sorted(res, key=len)\n",
    "    for i in range(len(strings)):\n",
    "        for j in range(i+1, len(strings)):\n",
    "            if strings[j].startswith(strings[i]):\n",
    "                res.remove(strings[i])\n",
    "                break\n",
    "    return list(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beauty & health > sexual wellness > sex toys > afrodisiac',\n",
       " 'beauty & health > sexual wellness > safer sex > lubricants']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_prefix_strings(['beauty & health > sexual wellness > safer sex > lubricants',\n",
    "   'beauty & health > sexual wellness > sex toys > afrodisiac',\n",
    "   'beauty & health',\n",
    "   'beauty & health > sexual wellness > safer sex > lubricants'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group['category_dedup'] = df_group['category'].apply(remove_prefix_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'purchases',\n",
       "  'category': [\"women's clothing > tops > tees\",\n",
       "   'automobiles & motorcycles > motorcycle accessories & parts > protective gear > shirts & tops',\n",
       "   \"women's clothing\",\n",
       "   'automobiles & motorcycles > motorcycle accessories & parts',\n",
       "   'unknown'],\n",
       "  'split': ['infer_train',\n",
       "   'infer_train',\n",
       "   'infer_train',\n",
       "   'infer_train',\n",
       "   'label_train'],\n",
       "  'category_dedup': [\"women's clothing > tops > tees\",\n",
       "   'unknown',\n",
       "   'automobiles & motorcycles > motorcycle accessories & parts > protective gear > shirts & tops']},\n",
       " {'query': 'blue',\n",
       "  'category': ['toys & hobbies > stuffed animals & plush toys > movies & tv',\n",
       "   'jewelry & accessories > necklaces & pendants > pendants',\n",
       "   'jewelry & accessories > fine jewelry > earrings',\n",
       "   'unknown'],\n",
       "  'split': ['infer_train', 'infer_train', 'infer_train', 'label_train'],\n",
       "  'category_dedup': ['unknown',\n",
       "   'jewelry & accessories > necklaces & pendants > pendants',\n",
       "   'jewelry & accessories > fine jewelry > earrings',\n",
       "   'toys & hobbies > stuffed animals & plush toys > movies & tv']},\n",
       " {'query': 'ハイキュー',\n",
       "  'category': ['toys & hobbies > classic toys > stickers',\n",
       "   'toys & hobbies > classic toys',\n",
       "   'toys & hobbies',\n",
       "   'unknown'],\n",
       "  'split': ['infer_train', 'infer_train', 'infer_train', 'label_train'],\n",
       "  'category_dedup': ['toys & hobbies > classic toys > stickers', 'unknown']},\n",
       " {'query': 'ösen',\n",
       "  'category': ['home & garden > arts, crafts & sewing > apparel sewing & fabric > garment eyelets',\n",
       "   'home improvement > hardware > brackets & clamps > clamps',\n",
       "   'home & garden > arts, crafts & sewing',\n",
       "   'unknown'],\n",
       "  'split': ['infer_train', 'infer_train', 'infer_train', 'label_train'],\n",
       "  'category_dedup': ['unknown',\n",
       "   'home & garden > arts, crafts & sewing > apparel sewing & fabric > garment eyelets',\n",
       "   'home improvement > hardware > brackets & clamps > clamps']},\n",
       " {'query': 'stazione meteorologica',\n",
       "  'category': ['home & garden > home decor > clocks > digital & analog-digital clocks',\n",
       "   'tools > measurement & analysis instruments > temperature instruments',\n",
       "   'home & garden',\n",
       "   'tools',\n",
       "   'unknown'],\n",
       "  'split': ['infer_train',\n",
       "   'infer_train',\n",
       "   'infer_train',\n",
       "   'infer_train',\n",
       "   'label_train'],\n",
       "  'category_dedup': ['tools > measurement & analysis instruments > temperature instruments',\n",
       "   'home & garden > home decor > clocks > digital & analog-digital clocks',\n",
       "   'unknown']}]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_group[df_group.category_dedup.apply(lambda x: 'unknown' in x and len(x) > 1)].sample(5).to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group.loc[df_group.category_dedup.apply(lambda x: 'unknown' in x), 'category_dedup'] = df_group.loc[\n",
    "    df_group.category_dedup.apply(lambda x: 'unknown' in x), 'category_dedup'].apply(lambda x: [\"unknown\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'newest',\n",
       "  'category': ['unknown'],\n",
       "  'split': ['label_train'],\n",
       "  'category_dedup': ['unknown']},\n",
       " {'query': 'brindes gratis',\n",
       "  'category': ['unknown'],\n",
       "  'split': ['label_train'],\n",
       "  'category_dedup': ['unknown']},\n",
       " {'query': 'samen pflanzen',\n",
       "  'category': ['unknown'],\n",
       "  'split': ['label_test'],\n",
       "  'category_dedup': ['unknown']},\n",
       " {'query': 'resortera',\n",
       "  'category': ['toys & hobbies > outdoor fun & sports > toy sports',\n",
       "   'toys & hobbies > outdoor fun & sports',\n",
       "   'toys & hobbies',\n",
       "   'unknown'],\n",
       "  'split': ['infer_train', 'infer_train', 'infer_train', 'label_train'],\n",
       "  'category_dedup': ['unknown']},\n",
       " {'query': 'return policy',\n",
       "  'category': ['home & garden > festive & party supplies > event & party > party favors',\n",
       "   'home & garden > festive & party supplies > event & party',\n",
       "   'home & garden',\n",
       "   'unknown'],\n",
       "  'split': ['infer_train', 'infer_train', 'infer_train', 'label_train'],\n",
       "  'category_dedup': ['unknown']}]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_group[df_group.category_dedup.apply(lambda x: 'unknown' in x)].sample(5).to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 4300, 17126, 2498981, 43294, 2846418)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_group_val = df_group[df_group.split.apply(lambda x: \"label_val\" in x)]\n",
    "df_group_test = df_group[df_group.split.apply(lambda x: \"label_test\" in x)]\n",
    "df_group_train_labelonly = df_group[df_group.split.apply(lambda x: \"label_train\" in x and \"infer_train\" not in x)]\n",
    "df_group_train_inferonly = df_group[df_group.split.apply(lambda x: \"infer_train\" in x and \"label_train\" not in x)]\n",
    "df_group_train_label_and_infer = df_group[df_group.split.apply(lambda x: \"infer_train\" in x and \"label_train\" in x)]\n",
    "len(df_group_val), len(df_group_test), len(df_group_train_labelonly), len(df_group_train_inferonly), len(df_group_train_label_and_infer), len(df_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2568701"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5000 + 4300 + 17126 + 2498981 + 43294"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.2041028408336372, 3.0389074970717584)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_group.category_dedup.apply(len).mean(), df_group.category.apply(len).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_group_test.split.apply(lambda x: len(set(x)) == 1).all()\n",
    "assert df_group_val.split.apply(lambda x: len(set(x)) == 1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dup_dfs = [df_group_test, df_group_val, df_group_train_labelonly, df_group_train_inferonly, df_group_train_label_and_infer]\n",
    "for i in range(len(test_dup_dfs)):\n",
    "    for j in range(i+1, len(test_dup_dfs)):\n",
    "        assert len(set(test_dup_dfs[i]['query']).intersection(set(test_dup_dfs[j]['query']))) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"processed3/Human_Labelled_Query_Classification_Test_DedupOverlap.json\", 'w') as f:\n",
    "    for i in df_group_test.to_dict('records'):\n",
    "        for j in i['category_dedup']:\n",
    "            f.write(json.dumps({\"query\": i[\"query\"], \"category\": j}) + \"\\n\")\n",
    "with open(\"processed3/Human_Labelled_Query_Classification_Val_DedupOverlap.json\", 'w') as f:\n",
    "    for i in df_group_val.to_dict('records'):\n",
    "        for j in i['category_dedup']:\n",
    "            f.write(json.dumps({\"query\": i[\"query\"], \"category\": j}) + \"\\n\")\n",
    "with open(\"processed3/OnlyHuman_Labelled_Query_Classification_Train_DedupOverlap.json\", 'w') as f:\n",
    "    for i in df_group_train_labelonly.to_dict('records'):\n",
    "        for j in i['category_dedup']:\n",
    "            f.write(json.dumps({\"query\": i[\"query\"], \"category\": j}) + \"\\n\")\n",
    "with open(\"processed3/OnlyInferred_Query_Classification_Train_DedupOverlap.json\", 'w') as f:\n",
    "    for i in df_group_train_inferonly.to_dict('records'):\n",
    "        for j in i['category_dedup']:\n",
    "            f.write(json.dumps({\"query\": i[\"query\"], \"category\": j}) + \"\\n\")\n",
    "with open(\"processed3/Mixed_Human_Inferred_Query_Classification_Train_DedupOverlap.json\", 'w') as f:\n",
    "    for i in df_group_train_label_and_infer.to_dict('records'):\n",
    "        for j in i['category_dedup']:\n",
    "            f.write(json.dumps({\"query\": i[\"query\"], \"category\": j}) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
